{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b0a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grupo: E | Periodos: 202520 ===\n",
      "Parámetros ingresos/deudas usados: año=2025, mes=6, salario_anual=14x\n",
      "\n",
      "--- Periodo 202520 ---\n",
      "Total hogares únicos: 12,731\n",
      "            ingreso_sobre_deuda  deuda_sobre_ingreso\n",
      "min                        0.00                 0.00\n",
      "max                2,038,400.00               664.93\n",
      "mediana                    0.73                 0.67\n",
      "media                    356.22                 2.90\n",
      "desviacion            23,680.17                12.23\n",
      "n                     10,969.00             9,797.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "# =========================================================\n",
    "# Config mapeos / alias de columnas y nombres de hojas\n",
    "# (ajusta aquí si tu archivo usa encabezados distintos)\n",
    "# =========================================================\n",
    "XLSX_PATH = Path(\"db/vulnerabilidad.xlsx\")\n",
    "\n",
    "SHEET_PERSONAS = \"Personas\"\n",
    "SHEET_UNIVERSO = \"Universo Familiares\"\n",
    "SHEET_INGRESOS = \"Ingresos\"\n",
    "SHEET_DEUDAS = \"Deudas\"\n",
    "\n",
    "# Dtype for IDs → todo texto\n",
    "DTYPE_DICT = {\n",
    "    \"identificacion\": str,\n",
    "    \"ruc_empleador\": str,\n",
    "    \"ced_padre\": str,\n",
    "    \"ced_madre\": str,\n",
    "}\n",
    "\n",
    "# Columnas esperadas (puedes mapear si difieren en tu xlsx)\n",
    "COL_PERIODO = \"periodo\"\n",
    "COL_IDENT = \"identificacion\"\n",
    "COL_TIPO = \"tipo\"  # 'A' (Afluentes) o 'E' (Enrollment)\n",
    "\n",
    "COL_CED_PADRE = \"ced_padre\"\n",
    "COL_CED_MADRE = \"ced_madre\"\n",
    "\n",
    "COL_ANIO = \"anio\"\n",
    "COL_MES = \"mes\"\n",
    "COL_SALARIO = \"salario\"  # ingreso mensual\n",
    "COL_DEUDA = \"valor\"  # deuda\n",
    "\n",
    "# Qué meses usar para ingresos y deudas (por defecto 2025-06)\n",
    "ANIO_FILTRO = 2025\n",
    "MES_FILTRO = 6\n",
    "\n",
    "# Multiplicador para llevar salario mensual a anual\n",
    "SALARIO_MESES_ANO = 14\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Helpers\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "def parse_monto(val) -> float:\n",
    "    if pd.isna(val):\n",
    "        return float(\"nan\")\n",
    "    s = str(val).strip()\n",
    "    if s == \"\":\n",
    "        return float(\"nan\")\n",
    "    # quita símbolos y cambia coma→punto\n",
    "    s = s.replace(\" \", \"\").replace(\"$\", \"\").replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "\n",
    "def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_hogar_id(ced_padre: str, ced_madre: str) -> str:\n",
    "    \"\"\"\n",
    "    Genera un ID de hogar estable:\n",
    "    - Si ambos '0' -> \"\"\n",
    "    - Si solo uno válido -> ese\n",
    "    - Si ambos válidos -> concatenación ordenada \"menor-mayor\"\n",
    "    \"\"\"\n",
    "    a = str(ced_padre or \"\").strip()\n",
    "    b = str(ced_madre or \"\").strip()\n",
    "    a = \"0\" if a == \"\" else a\n",
    "    b = \"0\" if b == \"\" else b\n",
    "    if a == \"0\" and b == \"0\":\n",
    "        return \"\"\n",
    "    if a == \"0\":\n",
    "        return b\n",
    "    if b == \"0\":\n",
    "        return a\n",
    "    return \"-\".join(sorted([a, b]))\n",
    "\n",
    "\n",
    "def _stats_from_series(s: pd.Series) -> dict:\n",
    "    \"\"\"Devuelve min, max, mediana, media, std y n para una serie numérica.\"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    s = s.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return {\n",
    "        \"min\": float(s.min()) if not s.empty else np.nan,\n",
    "        \"max\": float(s.max()) if not s.empty else np.nan,\n",
    "        \"mediana\": float(s.median()) if not s.empty else np.nan,\n",
    "        \"media\": float(s.mean()) if not s.empty else np.nan,\n",
    "        \"desviacion\": float(s.std(ddof=1)) if len(s) > 1 else 0.0,\n",
    "        \"n\": int(s.size),\n",
    "    }\n",
    "\n",
    "\n",
    "def _remove_outliers_iqr_series(s: pd.Series, k: float = 1.5) -> pd.Series:\n",
    "    \"\"\"Filtra outliers de una serie usando Tukey (IQR).\"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        return s\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low, high = q1 - k * iqr, q3 + k * iqr\n",
    "    return s[(s >= low) & (s <= high)]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Carga de datos desde el Excel\n",
    "# =========================================================\n",
    "def cargar_vulnerabilidad_xlsx(path: Path) -> dict:\n",
    "    # leemos todas las hojas, forzando columnas de ID a str\n",
    "    wb = pd.read_excel(\n",
    "        path,\n",
    "        sheet_name=None,\n",
    "        engine=\"openpyxl\",\n",
    "        dtype=DTYPE_DICT,  # 👈 aquí la normalización\n",
    "    )\n",
    "    # Normalizamos encabezados\n",
    "    data = {name: _norm_cols(df) for name, df in wb.items()}\n",
    "    return data\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ETL para familias, salarios, deudas (replicando tu lógica)\n",
    "# =========================================================\n",
    "def obtener_datos_familias(\n",
    "    dfs: dict, periodo: str, grupo_seleccionado: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Une Personas (filtrado por periodo y tipo) con Universo Familiares (padre/madre).\n",
    "    Filtra filas donde al menos un padre/madre sea válido (distinto de '0').\n",
    "    \"\"\"\n",
    "    df_personas = dfs.get(SHEET_PERSONAS, pd.DataFrame()).copy()\n",
    "    df_universo = dfs.get(SHEET_UNIVERSO, pd.DataFrame()).copy()\n",
    "    if df_personas.empty or df_universo.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Normaliza algunas columnas clave a string\n",
    "    for c in [COL_PERIODO, COL_IDENT, COL_TIPO]:\n",
    "        if c in df_personas.columns:\n",
    "            df_personas[c] = df_personas[c].astype(str).str.strip()\n",
    "\n",
    "    # Filtra por periodo y grupo (tipo)\n",
    "    personas_periodo = df_personas[\n",
    "        (df_personas[COL_PERIODO] == str(periodo))\n",
    "        & (df_personas[COL_TIPO] == str(grupo_seleccionado))\n",
    "    ].copy()\n",
    "    if personas_periodo.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Normaliza universo familiares\n",
    "    for c in [COL_IDENT, COL_CED_PADRE, COL_CED_MADRE]:\n",
    "        if c in df_universo.columns:\n",
    "            df_universo[c] = df_universo[c].astype(str).str.strip().replace({\"\": \"0\"})\n",
    "\n",
    "    familias = personas_periodo.merge(df_universo, on=COL_IDENT, how=\"left\")\n",
    "    familias = familias[\n",
    "        (familias[COL_CED_PADRE].fillna(\"0\") != \"0\")\n",
    "        | (familias[COL_CED_MADRE].fillna(\"0\") != \"0\")\n",
    "    ].copy()\n",
    "    return familias\n",
    "\n",
    "\n",
    "def obtener_datos_salario_deuda_familia(\n",
    "    dfs: dict, familias_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    if familias_df.empty:\n",
    "        return familias_df\n",
    "\n",
    "    out = familias_df.copy()\n",
    "    out[\"salario_familiar\"] = 0.0\n",
    "    out[\"deuda_familiar\"] = 0.0\n",
    "\n",
    "    # --- Ingresos (vectorizado) ---\n",
    "    df_ingresos = dfs.get(\"Ingresos\", pd.DataFrame()).copy()\n",
    "    if not df_ingresos.empty:\n",
    "        if \"salario\" in df_ingresos.columns:\n",
    "            df_ingresos[\"salario\"] = df_ingresos[\"salario\"].apply(parse_monto).fillna(0.0)\n",
    "        ingresos_mes = df_ingresos[\n",
    "            (df_ingresos[\"anio\"] == ANIO_FILTRO) & (df_ingresos[\"mes\"] == MES_FILTRO)\n",
    "        ].copy()\n",
    "\n",
    "        if not ingresos_mes.empty:\n",
    "            ing_por_id = ingresos_mes.groupby(\"identificacion\", as_index=False)[\n",
    "                \"salario\"\n",
    "            ].sum()\n",
    "            ing_map = dict(zip(ing_por_id[\"identificacion\"], ing_por_id[\"salario\"]))\n",
    "\n",
    "            s_padre = out[\"ced_padre\"].map(ing_map).fillna(0.0)\n",
    "            s_madre = out[\"ced_madre\"].map(ing_map).fillna(0.0)\n",
    "            out.loc[:, \"salario_familiar\"] = (s_padre + s_madre) * SALARIO_MESES_ANO\n",
    "\n",
    "    # --- Deudas (vectorizado) ---\n",
    "    df_deudas = dfs.get(\"Deudas\", pd.DataFrame()).copy()\n",
    "    if not df_deudas.empty:\n",
    "        if \"valor\" in df_deudas.columns:\n",
    "            df_deudas[\"valor\"] = df_deudas[\"valor\"].apply(parse_monto).fillna(0.0)\n",
    "        deudas_mes = df_deudas[\n",
    "            (df_deudas[\"anio\"] == ANIO_FILTRO) & (df_deudas[\"mes\"] == MES_FILTRO)\n",
    "        ].copy()\n",
    "\n",
    "        if not deudas_mes.empty:\n",
    "            deuda_por_id = deudas_mes.groupby(\"identificacion\", as_index=False)[\n",
    "                \"valor\"\n",
    "            ].sum()\n",
    "            deuda_map = dict(zip(deuda_por_id[\"identificacion\"], deuda_por_id[\"valor\"]))\n",
    "\n",
    "            d_padre = out[\"ced_padre\"].map(deuda_map).fillna(0.0)\n",
    "            d_madre = out[\"ced_madre\"].map(deuda_map).fillna(0.0)\n",
    "            out.loc[:, \"deuda_familiar\"] = d_padre + d_madre\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _hogares_unicos_salario_deuda(familias_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Condensa a 1 registro por hogar: hogar_id, salario_familiar, deuda_familiar.\n",
    "    \"\"\"\n",
    "    if familias_df.empty:\n",
    "        return pd.DataFrame(columns=[\"hogar_id\", \"salario_familiar\", \"deuda_familiar\"])\n",
    "\n",
    "    tmp = familias_df.copy()\n",
    "    tmp[COL_CED_PADRE] = tmp[COL_CED_PADRE].astype(str).str.strip().replace({\"\": \"0\"})\n",
    "    tmp[COL_CED_MADRE] = tmp[COL_CED_MADRE].astype(str).str.strip().replace({\"\": \"0\"})\n",
    "\n",
    "    tmp[\"hogar_id\"] = tmp.apply(\n",
    "        lambda r: make_hogar_id(r[COL_CED_PADRE], r[COL_CED_MADRE]), axis=1\n",
    "    )\n",
    "    tmp = tmp[tmp[\"hogar_id\"] != \"\"]\n",
    "\n",
    "    hogares = (\n",
    "        tmp.groupby(\"hogar_id\", as_index=False)[[\"salario_familiar\", \"deuda_familiar\"]]\n",
    "        .first()\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    hogares[\"salario_familiar\"] = pd.to_numeric(\n",
    "        hogares[\"salario_familiar\"], errors=\"coerce\"\n",
    "    ).fillna(0.0)\n",
    "    hogares[\"deuda_familiar\"] = pd.to_numeric(\n",
    "        hogares[\"deuda_familiar\"], errors=\"coerce\"\n",
    "    ).fillna(0.0)\n",
    "    hogares = hogares[\n",
    "        (hogares[\"salario_familiar\"] >= 0) & (hogares[\"deuda_familiar\"] >= 0)\n",
    "    ]\n",
    "    return hogares\n",
    "\n",
    "\n",
    "def calcular_estadisticas_ratios(\n",
    "    df_hogares: pd.DataFrame, remover_outliers: bool = False, k_iqr: float = 1.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Espera un DF con columnas salario_familiar (anual) y deuda_familiar (total).\n",
    "    Calcula stats para:\n",
    "      1) ingreso_anual / deuda_total  (denominador > 0)\n",
    "      2) deuda_total / ingreso_anual  (denominador > 0)\n",
    "    \"\"\"\n",
    "    idx = [\"min\", \"max\", \"mediana\", \"media\", \"desviacion\", \"n\"]\n",
    "    if df_hogares.empty:\n",
    "        return pd.DataFrame(\n",
    "            index=idx, columns=[\"ingreso_sobre_deuda\", \"deuda_sobre_ingreso\"]\n",
    "        )\n",
    "\n",
    "    r1_mask = df_hogares[\"deuda_familiar\"] > 0\n",
    "    r2_mask = df_hogares[\"salario_familiar\"] > 0\n",
    "\n",
    "    r1 = (\n",
    "        df_hogares.loc[r1_mask, \"salario_familiar\"]\n",
    "        / df_hogares.loc[r1_mask, \"deuda_familiar\"]\n",
    "    )\n",
    "    r2 = (\n",
    "        df_hogares.loc[r2_mask, \"deuda_familiar\"]\n",
    "        / df_hogares.loc[r2_mask, \"salario_familiar\"]\n",
    "    )\n",
    "\n",
    "    if remover_outliers:\n",
    "        r1 = _remove_outliers_iqr_series(r1, k=k_iqr)\n",
    "        r2 = _remove_outliers_iqr_series(r2, k=k_iqr)\n",
    "\n",
    "    stats_r1 = _stats_from_series(r1)\n",
    "    stats_r2 = _stats_from_series(r2)\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"ingreso_sobre_deuda\": stats_r1,\n",
    "            \"deuda_sobre_ingreso\": stats_r2,\n",
    "        }\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Ejecución: por grupo (A/E) y por periodo(s)\n",
    "# =========================================================\n",
    "def ejecutar_consola(\n",
    "    grupo_seleccionado: str, remover_outliers: bool = True, k_iqr: float = 1.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Imprime en consola las estadísticas para cada periodo disponible del grupo indicado.\n",
    "    grupo_seleccionado: 'A' (Afluentes) o 'E' (Enrollment)\n",
    "    \"\"\"\n",
    "    dfs = cargar_vulnerabilidad_xlsx(XLSX_PATH)\n",
    "    df_personas = dfs.get(SHEET_PERSONAS, pd.DataFrame()).copy()\n",
    "    if df_personas.empty:\n",
    "        print(\"No se encontró la hoja 'Personas' o está vacía.\")\n",
    "        return\n",
    "\n",
    "    # Periodos disponibles para el grupo\n",
    "    mask_grupo = df_personas[COL_TIPO].astype(str).str.strip() == str(\n",
    "        grupo_seleccionado\n",
    "    )\n",
    "    periodos = (\n",
    "        df_personas.loc[mask_grupo, COL_PERIODO]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .drop_duplicates()\n",
    "        .sort_values()\n",
    "        .tolist()\n",
    "    )\n",
    "    if not periodos:\n",
    "        print(f\"No hay periodos para el grupo {grupo_seleccionado}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== Grupo: {grupo_seleccionado} | Periodos: {', '.join(periodos)} ===\")\n",
    "    print(\n",
    "        f\"Parámetros ingresos/deudas usados: año={ANIO_FILTRO}, mes={MES_FILTRO}, salario_anual={SALARIO_MESES_ANO}x\\n\"\n",
    "    )\n",
    "\n",
    "    for periodo in periodos:\n",
    "        familias = obtener_datos_familias(dfs, periodo, grupo_seleccionado)\n",
    "        if familias.empty:\n",
    "            print(f\"[{periodo}] Sin familias.\")\n",
    "            continue\n",
    "\n",
    "        familias_sd = obtener_datos_salario_deuda_familia(dfs, familias)\n",
    "        hogares = _hogares_unicos_salario_deuda(familias_sd)\n",
    "\n",
    "        stats = calcular_estadisticas_ratios(\n",
    "            hogares, remover_outliers=remover_outliers, k_iqr=k_iqr\n",
    "        )\n",
    "\n",
    "        print(f\"--- Periodo {periodo} ---\")\n",
    "        print(f\"Total hogares únicos: {len(hogares):,}\")\n",
    "        print(stats.to_string())\n",
    "        print()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# MAIN (ajusta grupo según necesites)\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Ejecuta para Enrollment (E) y Afluentes (A) si quieres\n",
    "    ejecutar_consola(grupo_seleccionado=\"E\", remover_outliers=False, k_iqr=1.5)\n",
    "    # ejecutar_consola(grupo_seleccionado=\"A\", remover_outliers=True, k_iqr=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa81c049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando archivo: db\\vulnerabilidad.xlsx\n",
      "Total hogares filtrados: 8492\n",
      "Hogares 'raros' (n_personas_unicas < 2): 0\n",
      "Archivo generado: db\\hogares_raros_20250923_123733.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hogar_id</th>\n",
       "      <th>n_personas_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hogar_id, n_personas_unicas]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hogar_id</th>\n",
       "      <th>fam_id</th>\n",
       "      <th>identificacion</th>\n",
       "      <th>tipo_empleo</th>\n",
       "      <th>salario</th>\n",
       "      <th>tipo_empleo_mes6</th>\n",
       "      <th>trabaja_mes6</th>\n",
       "      <th>identificacion_est</th>\n",
       "      <th>ced_padre</th>\n",
       "      <th>ced_madre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hogar_id, fam_id, identificacion, tipo_empleo, salario, tipo_empleo_mes6, trabaja_mes6, identificacion_est, ced_padre, ced_madre]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ==========================\n",
    "# Config (ajusta si quieres)\n",
    "# ==========================\n",
    "DB_DIR = Path(\"db\")\n",
    "SHEET_UNIVERSO = \"Universo Familiares\"\n",
    "SHEET_PERSONAS = \"Personas\"  # opcional\n",
    "SHEET_INGRESOS = \"Ingresos\"  # requerido para 'trabajando'\n",
    "FILE_NAME = None  # si conoces el nombre, ponlo: \"vulnerabilidad.xlsx\"\n",
    "PERIODO = None  # ejemplo: \"2024-1\" o None para no filtrar por periodo\n",
    "ANIO = 2025\n",
    "MES = 6\n",
    "EMPLEOS_VALIDOS = [\"Relacion de Dependencia\", \"Afiliacion Voluntaria\"]\n",
    "\n",
    "# Filtros que quieres replicar del caso:\n",
    "CANT_PAPAS = 2  # 1, 2, o None (para Todos)\n",
    "CANT_PAPAS_TRAB = 1  # 0, 1, 2, o None (para Todos)\n",
    "TIPO_EMPLEO = \"Todos\"  # \"Todos\" | \"Relacion de Dependencia\" | \"Afiliacion Voluntaria\" | \"Desconocido\"\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Helpers\n",
    "# ==========================\n",
    "def make_hogar_id(ced_padre: str, ced_madre: str) -> str:\n",
    "    \"\"\"\n",
    "    Replica la idea de hogar único, independiente del orden.\n",
    "    Ignora \"0\" como no-informativo.\n",
    "    \"\"\"\n",
    "    a = str(ced_padre).strip()\n",
    "    b = str(ced_madre).strip()\n",
    "    ids = [x for x in (a, b) if x and x != \"0\"]\n",
    "    if not ids:\n",
    "        return \"\"\n",
    "    ids = sorted(ids)\n",
    "    return \"|\".join(ids)\n",
    "\n",
    "\n",
    "def load_excel_auto(db_dir: Path, file_name: str | None):\n",
    "    if file_name:\n",
    "        fp = db_dir / file_name\n",
    "        if not fp.exists():\n",
    "            raise FileNotFoundError(f\"No se encontró: {fp}\")\n",
    "        return fp\n",
    "    cands = list(db_dir.glob(\"*.xls*\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"No se encontró ningún Excel en db/\")\n",
    "    return cands[0]\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 1) Cargar hojas\n",
    "# ==========================\n",
    "file_path = load_excel_auto(DB_DIR, FILE_NAME)\n",
    "print(f\"Usando archivo: {file_path}\")\n",
    "\n",
    "xl = pd.ExcelFile(file_path)\n",
    "if SHEET_UNIVERSO not in xl.sheet_names:\n",
    "    raise KeyError(f\"No existe la hoja '{SHEET_UNIVERSO}' en el archivo.\")\n",
    "\n",
    "df_univ = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_UNIVERSO, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "df_univ.columns = [c.strip() for c in df_univ.columns]\n",
    "\n",
    "# PERSONAS (opcional, para filtrar por periodo)\n",
    "df_personas = None\n",
    "if SHEET_PERSONAS in xl.sheet_names:\n",
    "    df_personas = pd.read_excel(\n",
    "        file_path, sheet_name=SHEET_PERSONAS, dtype=str, engine=\"openpyxl\"\n",
    "    )\n",
    "    df_personas.columns = [c.strip() for c in df_personas.columns]\n",
    "\n",
    "# INGRESOS (requerido para n_trab y tipo)\n",
    "if SHEET_INGRESOS not in xl.sheet_names:\n",
    "    raise KeyError(f\"No existe la hoja '{SHEET_INGRESOS}' en el archivo.\")\n",
    "df_ing = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_INGRESOS, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "df_ing.columns = [c.strip() for c in df_ing.columns]\n",
    "\n",
    "# ==========================\n",
    "# 2) Normalización mínima\n",
    "# ==========================\n",
    "# Universo\n",
    "req_cols_univ = {\"identificacion\", \"ced_padre\", \"ced_madre\"}\n",
    "lower_map = {c: c.lower() for c in df_univ.columns}\n",
    "df_univ = df_univ.rename(columns=lower_map)\n",
    "faltan = req_cols_univ - set(df_univ.columns)\n",
    "if faltan:\n",
    "    raise KeyError(f\"En '{SHEET_UNIVERSO}' faltan columnas: {faltan}\")\n",
    "\n",
    "df_univ[\"ced_padre\"] = df_univ[\"ced_padre\"].astype(str).str.strip()\n",
    "df_univ[\"ced_madre\"] = df_univ[\"ced_madre\"].astype(str).str.strip()\n",
    "df_univ[\"hogar_id\"] = df_univ.apply(\n",
    "    lambda r: make_hogar_id(r[\"ced_padre\"], r[\"ced_madre\"]), axis=1\n",
    ")\n",
    "df_univ = df_univ[\n",
    "    (df_univ[\"hogar_id\"] != \"\")\n",
    "    & ((df_univ[\"ced_padre\"] != \"0\") | (df_univ[\"ced_madre\"] != \"0\"))\n",
    "].copy()\n",
    "\n",
    "# Personas (opcional: filtrar por periodo)\n",
    "if df_personas is not None:\n",
    "    df_personas = df_personas.rename(\n",
    "        columns={c: c.lower() for c in df_personas.columns}\n",
    "    )\n",
    "    if PERIODO is not None:\n",
    "        if (\n",
    "            \"periodo\" not in df_personas.columns\n",
    "            or \"identificacion\" not in df_personas.columns\n",
    "        ):\n",
    "            raise KeyError(\n",
    "                f\"En '{SHEET_PERSONAS}' faltan 'periodo' y/o 'identificacion' para filtrar.\"\n",
    "            )\n",
    "        ids_periodo = (\n",
    "            df_personas.loc[df_personas[\"periodo\"] == str(PERIODO), \"identificacion\"]\n",
    "            .dropna()\n",
    "            .unique()\n",
    "        )\n",
    "        df_univ = df_univ[df_univ[\"identificacion\"].isin(ids_periodo)].copy()\n",
    "\n",
    "# Ingresos JUN/2025\n",
    "df_ing = df_ing.rename(columns={c: c.lower() for c in df_ing.columns})\n",
    "req_cols_ing = {\"identificacion\", \"anio\", \"mes\", \"tipo_empleo\", \"salario\"}\n",
    "faltan_ing = req_cols_ing - set(df_ing.columns)\n",
    "if faltan_ing:\n",
    "    raise KeyError(f\"En '{SHEET_INGRESOS}' faltan columnas: {faltan_ing}\")\n",
    "\n",
    "df_ing = df_ing[\n",
    "    (df_ing[\"anio\"].astype(str) == str(ANIO)) & (df_ing[\"mes\"].astype(str) == str(MES))\n",
    "].copy()\n",
    "df_ing[\"tipo_empleo\"] = df_ing[\"tipo_empleo\"].astype(str).str.strip()\n",
    "df_ing[\"salario\"] = pd.to_numeric(df_ing[\"salario\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 3) Aplicar filtros como en tu app (Enrollment)\n",
    "# ==========================\n",
    "# 3.1 Contar papás DISTINCT (ignora \"0\")\n",
    "def count_distinct_parents(row):\n",
    "    s = {row[\"ced_padre\"], row[\"ced_madre\"]}\n",
    "    s.discard(\"0\")\n",
    "    return len(s)\n",
    "\n",
    "\n",
    "df_univ[\"n_papas\"] = df_univ.apply(count_distinct_parents, axis=1)\n",
    "if CANT_PAPAS in (1, 2):\n",
    "    df_univ = df_univ[df_univ[\"n_papas\"] == CANT_PAPAS].copy()\n",
    "\n",
    "# 3.2 Mapa hogar_id -> fam_id (padre/madre, sin \"0\")\n",
    "pairs = []\n",
    "for _, r in df_univ.iterrows():\n",
    "    if r[\"ced_padre\"] != \"0\":\n",
    "        pairs.append((r[\"hogar_id\"], r[\"ced_padre\"]))\n",
    "    if r[\"ced_madre\"] != \"0\":\n",
    "        pairs.append((r[\"hogar_id\"], r[\"ced_madre\"]))\n",
    "df_mapa = pd.DataFrame(pairs, columns=[\"hogar_id\", \"fam_id\"]).drop_duplicates()\n",
    "\n",
    "# 3.3 Merge con ingresos mes6\n",
    "df_emp = df_mapa.merge(\n",
    "    df_ing[[\"identificacion\", \"tipo_empleo\", \"salario\"]],\n",
    "    left_on=\"fam_id\",\n",
    "    right_on=\"identificacion\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df_emp[\"tipo_empleo_mes6\"] = df_emp[\"tipo_empleo\"].where(\n",
    "    df_emp[\"tipo_empleo\"].isin(EMPLEOS_VALIDOS), \"Desconocido\"\n",
    ")\n",
    "df_emp[\"trabaja_mes6\"] = df_emp[\"tipo_empleo_mes6\"].isin(EMPLEOS_VALIDOS)\n",
    "\n",
    "# 3.4 Filtro por tipo de empleo (si no es \"Todos\")\n",
    "if TIPO_EMPLEO != \"Todos\":\n",
    "    df_emp = df_emp[df_emp[\"tipo_empleo_mes6\"] == TIPO_EMPLEO].copy()\n",
    "\n",
    "# 3.5 Filtro por cantidad de papás trabajando (0/1/2)\n",
    "agg = df_emp.groupby(\"hogar_id\", as_index=False).agg(n_trab=(\"trabaja_mes6\", \"sum\"))\n",
    "if CANT_PAPAS_TRAB in (0, 1, 2):\n",
    "    agg = agg[agg[\"n_trab\"] == CANT_PAPAS_TRAB].copy()\n",
    "\n",
    "hogares_filtrados = set(agg[\"hogar_id\"])\n",
    "df_emp = df_emp[df_emp[\"hogar_id\"].isin(hogares_filtrados)].copy()\n",
    "\n",
    "# ==========================\n",
    "# 4) Detección de hogares \"raros\"\n",
    "#    (esperaríamos 2 personas únicas; encontramos < 2)\n",
    "# ==========================\n",
    "by_hogar = (\n",
    "    df_emp.groupby(\"hogar_id\")[\"fam_id\"].nunique().reset_index(name=\"n_personas_unicas\")\n",
    ")\n",
    "hogares_raros = by_hogar[by_hogar[\"n_personas_unicas\"] < 2].copy()\n",
    "\n",
    "print(f\"Total hogares filtrados: {len(hogares_filtrados)}\")\n",
    "print(f\"Hogares 'raros' (n_personas_unicas < 2): {len(hogares_raros)}\")\n",
    "\n",
    "# Detalle por hogar raro: qué fam_id trae, con qué tipo_empleo y salario\n",
    "detalle_raros = df_emp[df_emp[\"hogar_id\"].isin(set(hogares_raros[\"hogar_id\"]))].copy()\n",
    "# agrega info original del universo (ced_padre/ced_madre) para diagnósticos\n",
    "detalle_raros = detalle_raros.merge(\n",
    "    df_univ[[\"hogar_id\", \"identificacion\", \"ced_padre\", \"ced_madre\"]].drop_duplicates(),\n",
    "    on=\"hogar_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_est\"),\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# 5) Exportar a Excel (2 hojas)\n",
    "# ==========================\n",
    "out_name = f\"hogares_raros_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "out_path = file_path.parent / out_name\n",
    "\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as xw:\n",
    "    hogares_raros.to_excel(xw, index=False, sheet_name=\"hogares_raros_resumen\")\n",
    "    detalle_raros.to_excel(xw, index=False, sheet_name=\"hogares_raros_detalle\")\n",
    "\n",
    "print(f\"Archivo generado: {out_path}\")\n",
    "display(hogares_raros.head(10))\n",
    "display(detalle_raros.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ed58ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ Columnas no presentes en detalle_multi y serán omitidas: ['identificacion']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fam_id</th>\n",
       "      <th>hogar_id</th>\n",
       "      <th>rol_en_hogar</th>\n",
       "      <th>trabaja_mes6</th>\n",
       "      <th>tipo_empleo_mes6</th>\n",
       "      <th>salario</th>\n",
       "      <th>ced_padre</th>\n",
       "      <th>ced_madre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0502367485</td>\n",
       "      <td>0502367485|0502506215</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>470.00</td>\n",
       "      <td>0502506215</td>\n",
       "      <td>0502367485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0502367485</td>\n",
       "      <td>0502367485|1803303641</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>470.00</td>\n",
       "      <td>1803303641</td>\n",
       "      <td>0502367485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0603142324</td>\n",
       "      <td>0603142324|1001987864</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>550.00</td>\n",
       "      <td>1001987864</td>\n",
       "      <td>0603142324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0603142324</td>\n",
       "      <td>0603142324|1714146741</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>550.00</td>\n",
       "      <td>1714146741</td>\n",
       "      <td>0603142324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001660545</td>\n",
       "      <td>1001660545|1002120432</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001660545</td>\n",
       "      <td>1002120432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1001660545</td>\n",
       "      <td>1001660545|1709880262</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001660545</td>\n",
       "      <td>1709880262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1002177341</td>\n",
       "      <td>1002177341|1002524872</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002177341</td>\n",
       "      <td>1002524872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1002177341</td>\n",
       "      <td>1002177341|1002698551</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002177341</td>\n",
       "      <td>1002698551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1002527750</td>\n",
       "      <td>1001986254|1002527750</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1001986254</td>\n",
       "      <td>1002527750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1002527750</td>\n",
       "      <td>1002527750|1705318283</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1705318283</td>\n",
       "      <td>1002527750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1202488100</td>\n",
       "      <td>0906716774|1202488100</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>470.00</td>\n",
       "      <td>0906716774</td>\n",
       "      <td>1202488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1202488100</td>\n",
       "      <td>0909531212|1202488100</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>470.00</td>\n",
       "      <td>0909531212</td>\n",
       "      <td>1202488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1308909264</td>\n",
       "      <td>1308909264|1705620431</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>1676.00</td>\n",
       "      <td>1705620431</td>\n",
       "      <td>1308909264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1308909264</td>\n",
       "      <td>1308909264|1709536690</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>1676.00</td>\n",
       "      <td>1709536690</td>\n",
       "      <td>1308909264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1600541526</td>\n",
       "      <td>1002355236|1600541526</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>986.00</td>\n",
       "      <td>1002355236</td>\n",
       "      <td>1600541526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1600541526</td>\n",
       "      <td>1600541526|1802684223</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>986.00</td>\n",
       "      <td>1802684223</td>\n",
       "      <td>1600541526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1706952627</td>\n",
       "      <td>1706952627|1707259238</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>511.35</td>\n",
       "      <td>1707259238</td>\n",
       "      <td>1706952627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1706952627</td>\n",
       "      <td>1706952627|1710553932</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>511.35</td>\n",
       "      <td>1710553932</td>\n",
       "      <td>1706952627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1709443020</td>\n",
       "      <td>1709443020|1712670189</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1709443020</td>\n",
       "      <td>1712670189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1709443020</td>\n",
       "      <td>1709443020|1715735526</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1709443020</td>\n",
       "      <td>1715735526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fam_id               hogar_id rol_en_hogar  trabaja_mes6  \\\n",
       "0   0502367485  0502367485|0502506215        madre          True   \n",
       "1   0502367485  0502367485|1803303641        madre          True   \n",
       "44  0603142324  0603142324|1001987864        madre          True   \n",
       "43  0603142324  0603142324|1714146741        madre          True   \n",
       "7   1001660545  1001660545|1002120432        padre         False   \n",
       "5   1001660545  1001660545|1709880262        padre         False   \n",
       "8   1002177341  1002177341|1002524872        padre         False   \n",
       "6   1002177341  1002177341|1002698551        padre         False   \n",
       "11  1002527750  1001986254|1002527750        madre          True   \n",
       "46  1002527750  1002527750|1705318283        madre          True   \n",
       "3   1202488100  0906716774|1202488100        madre          True   \n",
       "4   1202488100  0909531212|1202488100        madre          True   \n",
       "40  1308909264  1308909264|1705620431        madre          True   \n",
       "41  1308909264  1308909264|1709536690        madre          True   \n",
       "9   1600541526  1002355236|1600541526        madre          True   \n",
       "10  1600541526  1600541526|1802684223        madre          True   \n",
       "16  1706952627  1706952627|1707259238        madre          True   \n",
       "13  1706952627  1706952627|1710553932        madre          True   \n",
       "31  1709443020  1709443020|1712670189        padre         False   \n",
       "12  1709443020  1709443020|1715735526        padre         False   \n",
       "\n",
       "           tipo_empleo_mes6  salario   ced_padre   ced_madre  \n",
       "0     Afiliacion Voluntaria   470.00  0502506215  0502367485  \n",
       "1     Afiliacion Voluntaria   470.00  1803303641  0502367485  \n",
       "44  Relacion de Dependencia   550.00  1001987864  0603142324  \n",
       "43  Relacion de Dependencia   550.00  1714146741  0603142324  \n",
       "7               Desconocido      NaN  1001660545  1002120432  \n",
       "5               Desconocido      NaN  1001660545  1709880262  \n",
       "8               Desconocido      NaN  1002177341  1002524872  \n",
       "6               Desconocido      NaN  1002177341  1002698551  \n",
       "11  Relacion de Dependencia  1000.00  1001986254  1002527750  \n",
       "46  Relacion de Dependencia  1000.00  1705318283  1002527750  \n",
       "3     Afiliacion Voluntaria   470.00  0906716774  1202488100  \n",
       "4     Afiliacion Voluntaria   470.00  0909531212  1202488100  \n",
       "40  Relacion de Dependencia  1676.00  1705620431  1308909264  \n",
       "41  Relacion de Dependencia  1676.00  1709536690  1308909264  \n",
       "9   Relacion de Dependencia   986.00  1002355236  1600541526  \n",
       "10  Relacion de Dependencia   986.00  1802684223  1600541526  \n",
       "16    Afiliacion Voluntaria   511.35  1707259238  1706952627  \n",
       "13    Afiliacion Voluntaria   511.35  1710553932  1706952627  \n",
       "31              Desconocido      NaN  1709443020  1712670189  \n",
       "12              Desconocido      NaN  1709443020  1715735526  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo generado: familiares_multi_hogar_20250923_124310.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 3D) orden y columnas útiles (robusto a columnas faltantes/acentos)\n",
    "# -------------------------------------------------\n",
    "# Normaliza posibles variantes con acento\n",
    "def _normalize_cols(df):\n",
    "    ren = {}\n",
    "    for c in df.columns:\n",
    "        cl = c.lower().strip()\n",
    "        # mapea variantes comunes\n",
    "        if cl in {\"identificación\", \"identificacion\"}:\n",
    "            ren[c] = \"identificacion\"\n",
    "        elif cl in {\"cedula_padre\", \"cédula_padre\"}:\n",
    "            ren[c] = \"ced_padre\"\n",
    "        elif cl in {\"cedula_madre\", \"cédula_madre\"}:\n",
    "            ren[c] = \"ced_madre\"\n",
    "        else:\n",
    "            ren[c] = c  # no cambiar\n",
    "    return df.rename(columns=ren)\n",
    "\n",
    "\n",
    "detalle_multi = _normalize_cols(detalle_multi)\n",
    "df_univ = _normalize_cols(df_univ)\n",
    "\n",
    "cols_show = [\n",
    "    \"fam_id\",\n",
    "    \"hogar_id\",\n",
    "    \"rol_en_hogar\",\n",
    "    \"trabaja_mes6\",\n",
    "    \"tipo_empleo_mes6\",\n",
    "    \"salario\",\n",
    "    \"identificacion\",\n",
    "    \"ced_padre\",\n",
    "    \"ced_madre\",\n",
    "]\n",
    "\n",
    "# Qué columnas realmente están\n",
    "existentes = [c for c in cols_show if c in detalle_multi.columns]\n",
    "faltantes = [c for c in cols_show if c not in detalle_multi.columns]\n",
    "if faltantes:\n",
    "    print(\"⚠️ Columnas no presentes en detalle_multi y serán omitidas:\", faltantes)\n",
    "\n",
    "detalle_multi = detalle_multi[existentes].sort_values([\"fam_id\", \"hogar_id\"])\n",
    "\n",
    "display(detalle_multi.head(20))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4) Exportar a Excel: resumen y detalle\n",
    "# -------------------------------------------------\n",
    "out_name = f\"familiares_multi_hogar_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "with pd.ExcelWriter(out_name, engine=\"openpyxl\") as xw:\n",
    "    multi_hogar.to_excel(xw, index=False, sheet_name=\"resumen_fam_multi_hogar\")\n",
    "    detalle_multi.to_excel(xw, index=False, sheet_name=\"detalle_fam_multi_hogar\")\n",
    "\n",
    "print(f\"Archivo generado: {out_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c32e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando archivo: db\\vulnerabilidad.xlsx\n",
      "Identificaciones en facultad 'FACULTAD DE CIENCIAS DE LA SALUD': 2145\n",
      "Hogares (tras filtro 2 papás): 1988\n",
      "Hogares filtrados finales: 842\n",
      "Familiares ÚNICOS - Trabajando: 841\n",
      "Familiares ÚNICOS - No Trabajando: 842\n",
      "Total ÚNICOS: 1683\n",
      "Esperado (= hogares × 2): 1684\n",
      "Familiares TRABAJANDO en >1 hogar: 1\n",
      "['1716691843']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['identificacion'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 241\u001b[39m\n\u001b[32m    229\u001b[39m detalle[\u001b[33m\"\u001b[39m\u001b[33mrol_en_hogar\u001b[39m\u001b[33m\"\u001b[39m] = detalle.apply(rol_en_hogar, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    231\u001b[39m cols_show = [\n\u001b[32m    232\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfam_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    233\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhogar_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    239\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mced_madre\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    240\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m detalle = \u001b[43mdetalle\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_show\u001b[49m\u001b[43m]\u001b[49m.sort_values([\u001b[33m\"\u001b[39m\u001b[33mfam_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhogar_id\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    243\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== DETALLE DE PERSONAS TRABAJANDO MULTI-HOGAR ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    244\u001b[39m display(detalle.head(\u001b[32m50\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andreidavid.flores\\Downloads\\Work\\Vulnerabilidad\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andreidavid.flores\\Downloads\\Work\\Vulnerabilidad\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andreidavid.flores\\Downloads\\Work\\Vulnerabilidad\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['identificacion'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ==========================\n",
    "# Config\n",
    "# ==========================\n",
    "DB_DIR = Path(\"db\")\n",
    "FILE_NAME =\"vulnerabilidad.xlsx\"\n",
    "SHEET_UNIVERSO = \"Universo Familiares\"\n",
    "SHEET_PERSONAS = \"Personas\"\n",
    "SHEET_INGRESOS = \"Ingresos\"\n",
    "FACULTAD_NAME = \"FACULTAD DE CIENCIAS DE LA SALUD\"\n",
    "\n",
    "ANIO = 2025\n",
    "MES = 6\n",
    "EMPLEOS_VALIDOS = [\"Relacion de Dependencia\", \"Afiliacion Voluntaria\"]\n",
    "\n",
    "# Filtros tal como los tienes:\n",
    "CANT_PAPAS = 2  # 1, 2 o None (\"Todos\")\n",
    "CANT_PAPAS_TRAB = 1  # 0, 1, 2 o None (\"Todos\")\n",
    "TIPO_EMPLEO = \"Todos\"  # \"Todos\" | \"Relacion de Dependencia\" | \"Afiliacion Voluntaria\" | \"Desconocido\"\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Helpers\n",
    "# ==========================\n",
    "def load_excel_auto(db_dir: Path, file_name: str | None) -> Path:\n",
    "    if file_name:\n",
    "        fp = db_dir / file_name\n",
    "        if not fp.exists():\n",
    "            raise FileNotFoundError(f\"No se encontró: {fp}\")\n",
    "        return fp\n",
    "    cands = list(db_dir.glob(\"*.xls*\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"No se encontró ningún Excel en db/\")\n",
    "    return cands[0]\n",
    "\n",
    "\n",
    "def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # normaliza a minúsculas y mapea variantes con acento\n",
    "    ren = {}\n",
    "    for c in df.columns:\n",
    "        cl = c.strip().lower()\n",
    "        if cl in {\"identificación\", \"identificacion\"}:\n",
    "            ren[c] = \"identificacion\"\n",
    "        elif cl in {\"facultad\"}:\n",
    "            ren[c] = \"facultad\"\n",
    "        elif cl in {\"cédula_padre\", \"cedula_padre\"}:\n",
    "            ren[c] = \"ced_padre\"\n",
    "        elif cl in {\"cédula_madre\", \"cedula_madre\"}:\n",
    "            ren[c] = \"ced_madre\"\n",
    "        elif cl in {\"año\"}:\n",
    "            ren[c] = \"anio\"\n",
    "        else:\n",
    "            ren[c] = cl\n",
    "    return df.rename(columns=ren)\n",
    "\n",
    "\n",
    "def make_hogar_id(ced_padre: str, ced_madre: str) -> str:\n",
    "    a = str(ced_padre).strip()\n",
    "    b = str(ced_madre).strip()\n",
    "    ids = [x for x in (a, b) if x and x != \"0\"]\n",
    "    if not ids:\n",
    "        return \"\"\n",
    "    return \"|\".join(sorted(ids))\n",
    "\n",
    "\n",
    "def count_distinct_parents(row) -> int:\n",
    "    s = {row[\"ced_padre\"], row[\"ced_madre\"]}\n",
    "    s.discard(\"0\")\n",
    "    return len(s)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 1) Cargar hojas\n",
    "# ==========================\n",
    "file_path = load_excel_auto(DB_DIR, FILE_NAME)\n",
    "print(f\"Usando archivo: {file_path}\")\n",
    "\n",
    "xl = pd.ExcelFile(file_path)\n",
    "for sh in (SHEET_UNIVERSO, SHEET_PERSONAS, SHEET_INGRESOS):\n",
    "    if sh not in xl.sheet_names:\n",
    "        raise KeyError(f\"No existe la hoja '{sh}' en el archivo.\")\n",
    "\n",
    "df_univ = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_UNIVERSO, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "df_per = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_PERSONAS, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "df_ing = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_INGRESOS, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "\n",
    "df_univ = normalize_cols(df_univ)\n",
    "df_per = normalize_cols(df_per)\n",
    "df_ing = normalize_cols(df_ing)\n",
    "\n",
    "# Validación mínima\n",
    "for req, df_ in (\n",
    "    ({\"identificacion\", \"ced_padre\", \"ced_madre\"}, df_univ),\n",
    "    ({\"identificacion\", \"facultad\"}, df_per),\n",
    "    ({\"identificacion\", \"anio\", \"mes\", \"tipo_empleo\", \"salario\"}, df_ing),\n",
    "):\n",
    "    faltan = req - set(df_.columns)\n",
    "    if faltan:\n",
    "        raise KeyError(\n",
    "            f\"Faltan columnas {faltan} en una de las hojas correspondientes.\"\n",
    "        )\n",
    "\n",
    "# ==========================\n",
    "# 2) Filtrar Personas por facultad\n",
    "# ==========================\n",
    "ids_facultad = (\n",
    "    df_per.loc[\n",
    "        df_per[\"facultad\"].astype(str).str.strip().str.lower() == FACULTAD_NAME.lower(),\n",
    "        \"identificacion\",\n",
    "    ]\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "print(f\"Identificaciones en facultad '{FACULTAD_NAME}': {len(ids_facultad)}\")\n",
    "\n",
    "# ==========================\n",
    "# 3) Universo filtrado por esos estudiantes\n",
    "# ==========================\n",
    "u = df_univ[df_univ[\"identificacion\"].isin(ids_facultad)].copy()\n",
    "u[\"ced_padre\"] = u[\"ced_padre\"].astype(str).str.strip()\n",
    "u[\"ced_madre\"] = u[\"ced_madre\"].astype(str).str.strip()\n",
    "u[\"hogar_id\"] = u.apply(lambda r: make_hogar_id(r[\"ced_padre\"], r[\"ced_madre\"]), axis=1)\n",
    "u = u[\n",
    "    (u[\"hogar_id\"] != \"\") & ((u[\"ced_padre\"] != \"0\") | (u[\"ced_madre\"] != \"0\"))\n",
    "].copy()\n",
    "\n",
    "# contar papás DISTINCT y filtrar 2\n",
    "u[\"n_papas\"] = u.apply(count_distinct_parents, axis=1)\n",
    "if CANT_PAPAS in (1, 2):\n",
    "    u = u[u[\"n_papas\"] == CANT_PAPAS].copy()\n",
    "\n",
    "print(\"Hogares (tras filtro 2 papás):\", u[\"hogar_id\"].nunique())\n",
    "\n",
    "# ==========================\n",
    "# 4) Ingresos JUN/2025 y merge a familiares\n",
    "# ==========================\n",
    "ing6 = df_ing[\n",
    "    (df_ing[\"anio\"].astype(str) == str(ANIO)) & (df_ing[\"mes\"].astype(str) == str(MES))\n",
    "].copy()\n",
    "ing6[\"tipo_empleo\"] = ing6[\"tipo_empleo\"].astype(str).str.strip()\n",
    "ing6[\"salario\"] = pd.to_numeric(ing6[\"salario\"], errors=\"coerce\")\n",
    "\n",
    "pairs = []\n",
    "for _, r in u.iterrows():\n",
    "    if r[\"ced_padre\"] != \"0\":\n",
    "        pairs.append((r[\"hogar_id\"], r[\"ced_padre\"]))\n",
    "    if r[\"ced_madre\"] != \"0\":\n",
    "        pairs.append((r[\"hogar_id\"], r[\"ced_madre\"]))\n",
    "df_mapa = pd.DataFrame(pairs, columns=[\"hogar_id\", \"fam_id\"]).drop_duplicates()\n",
    "\n",
    "df_emp = df_mapa.merge(\n",
    "    ing6[[\"identificacion\", \"tipo_empleo\", \"salario\"]],\n",
    "    left_on=\"fam_id\",\n",
    "    right_on=\"identificacion\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df_emp[\"tipo_empleo_mes6\"] = df_emp[\"tipo_empleo\"].where(\n",
    "    df_emp[\"tipo_empleo\"].isin(EMPLEOS_VALIDOS), \"Desconocido\"\n",
    ")\n",
    "df_emp[\"trabaja_mes6\"] = df_emp[\"tipo_empleo_mes6\"].isin(EMPLEOS_VALIDOS)\n",
    "\n",
    "# filtro por tipo empleo (si aplica)\n",
    "if TIPO_EMPLEO != \"Todos\":\n",
    "    df_emp = df_emp[df_emp[\"tipo_empleo_mes6\"] == TIPO_EMPLEO].copy()\n",
    "\n",
    "# hogares con exactamente 1 trabajando\n",
    "agg = df_emp.groupby(\"hogar_id\", as_index=False).agg(n_trab=(\"trabaja_mes6\", \"sum\"))\n",
    "if CANT_PAPAS_TRAB in (0, 1, 2):\n",
    "    agg = agg[agg[\"n_trab\"] == CANT_PAPAS_TRAB].copy()\n",
    "\n",
    "hogares_filtrados = set(agg[\"hogar_id\"])\n",
    "df_emp = df_emp[df_emp[\"hogar_id\"].isin(hogares_filtrados)].copy()\n",
    "\n",
    "print(\"Hogares filtrados finales:\", len(hogares_filtrados))\n",
    "\n",
    "# ==========================\n",
    "# 5) Ver la asimetría y detectar al/los causantes (TRABAJANDO)\n",
    "# ==========================\n",
    "# Esperado (si no hay solapes): #hogares trabajando únicos = #hogares\n",
    "trab = df_emp[df_emp[\"trabaja_mes6\"]].copy()\n",
    "no_trab = df_emp[~df_emp[\"trabaja_mes6\"]].copy()\n",
    "\n",
    "trab_unicos = trab[\"fam_id\"].nunique()\n",
    "no_trab_unicos = no_trab[\"fam_id\"].nunique()\n",
    "\n",
    "print(\"Familiares ÚNICOS - Trabajando:\", trab_unicos)\n",
    "print(\"Familiares ÚNICOS - No Trabajando:\", no_trab_unicos)\n",
    "print(\"Total ÚNICOS:\", trab_unicos + no_trab_unicos)\n",
    "print(\"Esperado (= hogares × 2):\", len(hogares_filtrados) * 2)\n",
    "\n",
    "# fam_id en >1 hogar dentro del set TRABAJANDO (estos causan que 842 -> 841)\n",
    "solapes_trab = trab.groupby(\"fam_id\")[\"hogar_id\"].nunique() > 1\n",
    "fam_multi_trab = solapes_trab[solapes_trab].index.tolist()\n",
    "\n",
    "print(\"Familiares TRABAJANDO en >1 hogar:\", len(fam_multi_trab))\n",
    "print(fam_multi_trab[:10])\n",
    "\n",
    "# ==========================\n",
    "# 6) Detalle del/los fam_id problemáticos\n",
    "# ==========================\n",
    "detalle = trab[trab[\"fam_id\"].isin(fam_multi_trab)].copy()\n",
    "# añade datos del universo para ver qué estudiante(s) los vincularon\n",
    "detalle = detalle.merge(\n",
    "    u[[\"hogar_id\", \"identificacion\", \"ced_padre\", \"ced_madre\"]].drop_duplicates(),\n",
    "    on=\"hogar_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "# rol en el hogar para mayor claridad\n",
    "def rol_en_hogar(row):\n",
    "    if row[\"fam_id\"] == row[\"ced_padre\"]:\n",
    "        return \"padre\"\n",
    "    if row[\"fam_id\"] == row[\"ced_madre\"]:\n",
    "        return \"madre\"\n",
    "    return \"desconocido\"\n",
    "\n",
    "\n",
    "detalle[\"rol_en_hogar\"] = detalle.apply(rol_en_hogar, axis=1)\n",
    "\n",
    "cols_show = [\n",
    "    \"fam_id\",\n",
    "    \"hogar_id\",\n",
    "    \"rol_en_hogar\",\n",
    "    \"tipo_empleo_mes6\",\n",
    "    \"salario\",\n",
    "    \"identificacion\",\n",
    "    \"ced_padre\",\n",
    "    \"ced_madre\",\n",
    "]\n",
    "detalle = detalle[cols_show].sort_values([\"fam_id\", \"hogar_id\"])\n",
    "\n",
    "print(\"\\n=== DETALLE DE PERSONAS TRABAJANDO MULTI-HOGAR ===\")\n",
    "display(detalle.head(50))\n",
    "\n",
    "# ==========================\n",
    "# 7) Exportar a Excel\n",
    "# ==========================\n",
    "out_name = f\"salud_personas_trabajando_multi_hogar_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "out_path = file_path.parent / out_name\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as xw:\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"hogares_filtrados\": [len(hogares_filtrados)],\n",
    "            \"trabajando_unicos\": [trab_unicos],\n",
    "            \"no_trabajando_unicos\": [no_trab_unicos],\n",
    "            \"total_unicos\": [trab_unicos + no_trab_unicos],\n",
    "            \"esperado_hogares_x2\": [len(hogares_filtrados) * 2],\n",
    "        }\n",
    "    ).to_excel(xw, index=False, sheet_name=\"resumen\")\n",
    "    pd.DataFrame({\"fam_id_multi_trab\": fam_multi_trab}).to_excel(\n",
    "        xw, index=False, sheet_name=\"ids_multi_trab\"\n",
    "    )\n",
    "    detalle.to_excel(xw, index=False, sheet_name=\"detalle_multi_trab\")\n",
    "\n",
    "print(f\"\\nArchivo generado: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
