{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b0a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Grupo: E | Periodos: 202520 ===\n",
      "Par√°metros ingresos/deudas usados: a√±o=2025, mes=6, salario_anual=14x\n",
      "\n",
      "--- Periodo 202520 ---\n",
      "Total hogares √∫nicos: 12,731\n",
      "            ingreso_sobre_deuda  deuda_sobre_ingreso\n",
      "min                        0.00                 0.00\n",
      "max                2,038,400.00               664.93\n",
      "mediana                    0.73                 0.67\n",
      "media                    356.22                 2.90\n",
      "desviacion            23,680.17                12.23\n",
      "n                     10,969.00             9,797.00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "pd.options.display.float_format = \"{:,.2f}\".format\n",
    "\n",
    "# =========================================================\n",
    "# Config mapeos / alias de columnas y nombres de hojas\n",
    "# (ajusta aqu√≠ si tu archivo usa encabezados distintos)\n",
    "# =========================================================\n",
    "XLSX_PATH = Path(\"db/vulnerabilidad.xlsx\")\n",
    "\n",
    "SHEET_PERSONAS = \"Personas\"\n",
    "SHEET_UNIVERSO = \"Universo Familiares\"\n",
    "SHEET_INGRESOS = \"Ingresos\"\n",
    "SHEET_DEUDAS = \"Deudas\"\n",
    "\n",
    "# Dtype for IDs ‚Üí todo texto\n",
    "DTYPE_DICT = {\n",
    "    \"identificacion\": str,\n",
    "    \"ruc_empleador\": str,\n",
    "    \"ced_padre\": str,\n",
    "    \"ced_madre\": str,\n",
    "}\n",
    "\n",
    "# Columnas esperadas (puedes mapear si difieren en tu xlsx)\n",
    "COL_PERIODO = \"periodo\"\n",
    "COL_IDENT = \"identificacion\"\n",
    "COL_TIPO = \"tipo\"  # 'A' (Afluentes) o 'E' (Enrollment)\n",
    "\n",
    "COL_CED_PADRE = \"ced_padre\"\n",
    "COL_CED_MADRE = \"ced_madre\"\n",
    "\n",
    "COL_ANIO = \"anio\"\n",
    "COL_MES = \"mes\"\n",
    "COL_SALARIO = \"salario\"  # ingreso mensual\n",
    "COL_DEUDA = \"valor\"  # deuda\n",
    "\n",
    "# Qu√© meses usar para ingresos y deudas (por defecto 2025-06)\n",
    "ANIO_FILTRO = 2025\n",
    "MES_FILTRO = 6\n",
    "\n",
    "# Multiplicador para llevar salario mensual a anual\n",
    "SALARIO_MESES_ANO = 14\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Helpers\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "def parse_monto(val) -> float:\n",
    "    if pd.isna(val):\n",
    "        return float(\"nan\")\n",
    "    s = str(val).strip()\n",
    "    if s == \"\":\n",
    "        return float(\"nan\")\n",
    "    # quita s√≠mbolos y cambia coma‚Üípunto\n",
    "    s = s.replace(\" \", \"\").replace(\"$\", \"\").replace(\",\", \".\")\n",
    "    try:\n",
    "        return float(s)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "\n",
    "def _norm_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_hogar_id(ced_padre: str, ced_madre: str) -> str:\n",
    "    \"\"\"\n",
    "    Genera un ID de hogar estable:\n",
    "    - Si ambos '0' -> \"\"\n",
    "    - Si solo uno v√°lido -> ese\n",
    "    - Si ambos v√°lidos -> concatenaci√≥n ordenada \"menor-mayor\"\n",
    "    \"\"\"\n",
    "    a = str(ced_padre or \"\").strip()\n",
    "    b = str(ced_madre or \"\").strip()\n",
    "    a = \"0\" if a == \"\" else a\n",
    "    b = \"0\" if b == \"\" else b\n",
    "    if a == \"0\" and b == \"0\":\n",
    "        return \"\"\n",
    "    if a == \"0\":\n",
    "        return b\n",
    "    if b == \"0\":\n",
    "        return a\n",
    "    return \"-\".join(sorted([a, b]))\n",
    "\n",
    "\n",
    "def _stats_from_series(s: pd.Series) -> dict:\n",
    "    \"\"\"Devuelve min, max, mediana, media, std y n para una serie num√©rica.\"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    s = s.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return {\n",
    "        \"min\": float(s.min()) if not s.empty else np.nan,\n",
    "        \"max\": float(s.max()) if not s.empty else np.nan,\n",
    "        \"mediana\": float(s.median()) if not s.empty else np.nan,\n",
    "        \"media\": float(s.mean()) if not s.empty else np.nan,\n",
    "        \"desviacion\": float(s.std(ddof=1)) if len(s) > 1 else 0.0,\n",
    "        \"n\": int(s.size),\n",
    "    }\n",
    "\n",
    "\n",
    "def _remove_outliers_iqr_series(s: pd.Series, k: float = 1.5) -> pd.Series:\n",
    "    \"\"\"Filtra outliers de una serie usando Tukey (IQR).\"\"\"\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        return s\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low, high = q1 - k * iqr, q3 + k * iqr\n",
    "    return s[(s >= low) & (s <= high)]\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Carga de datos desde el Excel\n",
    "# =========================================================\n",
    "def cargar_vulnerabilidad_xlsx(path: Path) -> dict:\n",
    "    # leemos todas las hojas, forzando columnas de ID a str\n",
    "    wb = pd.read_excel(\n",
    "        path,\n",
    "        sheet_name=None,\n",
    "        engine=\"openpyxl\",\n",
    "        dtype=DTYPE_DICT,  # üëà aqu√≠ la normalizaci√≥n\n",
    "    )\n",
    "    # Normalizamos encabezados\n",
    "    data = {name: _norm_cols(df) for name, df in wb.items()}\n",
    "    return data\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# ETL para familias, salarios, deudas (replicando tu l√≥gica)\n",
    "# =========================================================\n",
    "def obtener_datos_familias(\n",
    "    dfs: dict, periodo: str, grupo_seleccionado: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Une Personas (filtrado por periodo y tipo) con Universo Familiares (padre/madre).\n",
    "    Filtra filas donde al menos un padre/madre sea v√°lido (distinto de '0').\n",
    "    \"\"\"\n",
    "    df_personas = dfs.get(SHEET_PERSONAS, pd.DataFrame()).copy()\n",
    "    df_universo = dfs.get(SHEET_UNIVERSO, pd.DataFrame()).copy()\n",
    "    if df_personas.empty or df_universo.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Normaliza algunas columnas clave a string\n",
    "    for c in [COL_PERIODO, COL_IDENT, COL_TIPO]:\n",
    "        if c in df_personas.columns:\n",
    "            df_personas[c] = df_personas[c].astype(str).str.strip()\n",
    "\n",
    "    # Filtra por periodo y grupo (tipo)\n",
    "    personas_periodo = df_personas[\n",
    "        (df_personas[COL_PERIODO] == str(periodo))\n",
    "        & (df_personas[COL_TIPO] == str(grupo_seleccionado))\n",
    "    ].copy()\n",
    "    if personas_periodo.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Normaliza universo familiares\n",
    "    for c in [COL_IDENT, COL_CED_PADRE, COL_CED_MADRE]:\n",
    "        if c in df_universo.columns:\n",
    "            df_universo[c] = df_universo[c].astype(str).str.strip().replace({\"\": \"0\"})\n",
    "\n",
    "    familias = personas_periodo.merge(df_universo, on=COL_IDENT, how=\"left\")\n",
    "    familias = familias[\n",
    "        (familias[COL_CED_PADRE].fillna(\"0\") != \"0\")\n",
    "        | (familias[COL_CED_MADRE].fillna(\"0\") != \"0\")\n",
    "    ].copy()\n",
    "    return familias\n",
    "\n",
    "\n",
    "def obtener_datos_salario_deuda_familia(\n",
    "    dfs: dict, familias_df: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    if familias_df.empty:\n",
    "        return familias_df\n",
    "\n",
    "    out = familias_df.copy()\n",
    "    out[\"salario_familiar\"] = 0.0\n",
    "    out[\"deuda_familiar\"] = 0.0\n",
    "\n",
    "    # --- Ingresos (vectorizado) ---\n",
    "    df_ingresos = dfs.get(\"Ingresos\", pd.DataFrame()).copy()\n",
    "    if not df_ingresos.empty:\n",
    "        if \"salario\" in df_ingresos.columns:\n",
    "            df_ingresos[\"salario\"] = df_ingresos[\"salario\"].apply(parse_monto).fillna(0.0)\n",
    "        ingresos_mes = df_ingresos[\n",
    "            (df_ingresos[\"anio\"] == ANIO_FILTRO) & (df_ingresos[\"mes\"] == MES_FILTRO)\n",
    "        ].copy()\n",
    "\n",
    "        if not ingresos_mes.empty:\n",
    "            ing_por_id = ingresos_mes.groupby(\"identificacion\", as_index=False)[\n",
    "                \"salario\"\n",
    "            ].sum()\n",
    "            ing_map = dict(zip(ing_por_id[\"identificacion\"], ing_por_id[\"salario\"]))\n",
    "\n",
    "            s_padre = out[\"ced_padre\"].map(ing_map).fillna(0.0)\n",
    "            s_madre = out[\"ced_madre\"].map(ing_map).fillna(0.0)\n",
    "            out.loc[:, \"salario_familiar\"] = (s_padre + s_madre) * SALARIO_MESES_ANO\n",
    "\n",
    "    # --- Deudas (vectorizado) ---\n",
    "    df_deudas = dfs.get(\"Deudas\", pd.DataFrame()).copy()\n",
    "    if not df_deudas.empty:\n",
    "        if \"valor\" in df_deudas.columns:\n",
    "            df_deudas[\"valor\"] = df_deudas[\"valor\"].apply(parse_monto).fillna(0.0)\n",
    "        deudas_mes = df_deudas[\n",
    "            (df_deudas[\"anio\"] == ANIO_FILTRO) & (df_deudas[\"mes\"] == MES_FILTRO)\n",
    "        ].copy()\n",
    "\n",
    "        if not deudas_mes.empty:\n",
    "            deuda_por_id = deudas_mes.groupby(\"identificacion\", as_index=False)[\n",
    "                \"valor\"\n",
    "            ].sum()\n",
    "            deuda_map = dict(zip(deuda_por_id[\"identificacion\"], deuda_por_id[\"valor\"]))\n",
    "\n",
    "            d_padre = out[\"ced_padre\"].map(deuda_map).fillna(0.0)\n",
    "            d_madre = out[\"ced_madre\"].map(deuda_map).fillna(0.0)\n",
    "            out.loc[:, \"deuda_familiar\"] = d_padre + d_madre\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _hogares_unicos_salario_deuda(familias_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Condensa a 1 registro por hogar: hogar_id, salario_familiar, deuda_familiar.\n",
    "    \"\"\"\n",
    "    if familias_df.empty:\n",
    "        return pd.DataFrame(columns=[\"hogar_id\", \"salario_familiar\", \"deuda_familiar\"])\n",
    "\n",
    "    tmp = familias_df.copy()\n",
    "    tmp[COL_CED_PADRE] = tmp[COL_CED_PADRE].astype(str).str.strip().replace({\"\": \"0\"})\n",
    "    tmp[COL_CED_MADRE] = tmp[COL_CED_MADRE].astype(str).str.strip().replace({\"\": \"0\"})\n",
    "\n",
    "    tmp[\"hogar_id\"] = tmp.apply(\n",
    "        lambda r: make_hogar_id(r[COL_CED_PADRE], r[COL_CED_MADRE]), axis=1\n",
    "    )\n",
    "    tmp = tmp[tmp[\"hogar_id\"] != \"\"]\n",
    "\n",
    "    hogares = (\n",
    "        tmp.groupby(\"hogar_id\", as_index=False)[[\"salario_familiar\", \"deuda_familiar\"]]\n",
    "        .first()\n",
    "        .copy()\n",
    "    )\n",
    "\n",
    "    hogares[\"salario_familiar\"] = pd.to_numeric(\n",
    "        hogares[\"salario_familiar\"], errors=\"coerce\"\n",
    "    ).fillna(0.0)\n",
    "    hogares[\"deuda_familiar\"] = pd.to_numeric(\n",
    "        hogares[\"deuda_familiar\"], errors=\"coerce\"\n",
    "    ).fillna(0.0)\n",
    "    hogares = hogares[\n",
    "        (hogares[\"salario_familiar\"] >= 0) & (hogares[\"deuda_familiar\"] >= 0)\n",
    "    ]\n",
    "    return hogares\n",
    "\n",
    "\n",
    "def calcular_estadisticas_ratios(\n",
    "    df_hogares: pd.DataFrame, remover_outliers: bool = False, k_iqr: float = 1.5\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Espera un DF con columnas salario_familiar (anual) y deuda_familiar (total).\n",
    "    Calcula stats para:\n",
    "      1) ingreso_anual / deuda_total  (denominador > 0)\n",
    "      2) deuda_total / ingreso_anual  (denominador > 0)\n",
    "    \"\"\"\n",
    "    idx = [\"min\", \"max\", \"mediana\", \"media\", \"desviacion\", \"n\"]\n",
    "    if df_hogares.empty:\n",
    "        return pd.DataFrame(\n",
    "            index=idx, columns=[\"ingreso_sobre_deuda\", \"deuda_sobre_ingreso\"]\n",
    "        )\n",
    "\n",
    "    r1_mask = df_hogares[\"deuda_familiar\"] > 0\n",
    "    r2_mask = df_hogares[\"salario_familiar\"] > 0\n",
    "\n",
    "    r1 = (\n",
    "        df_hogares.loc[r1_mask, \"salario_familiar\"]\n",
    "        / df_hogares.loc[r1_mask, \"deuda_familiar\"]\n",
    "    )\n",
    "    r2 = (\n",
    "        df_hogares.loc[r2_mask, \"deuda_familiar\"]\n",
    "        / df_hogares.loc[r2_mask, \"salario_familiar\"]\n",
    "    )\n",
    "\n",
    "    if remover_outliers:\n",
    "        r1 = _remove_outliers_iqr_series(r1, k=k_iqr)\n",
    "        r2 = _remove_outliers_iqr_series(r2, k=k_iqr)\n",
    "\n",
    "    stats_r1 = _stats_from_series(r1)\n",
    "    stats_r2 = _stats_from_series(r2)\n",
    "\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"ingreso_sobre_deuda\": stats_r1,\n",
    "            \"deuda_sobre_ingreso\": stats_r2,\n",
    "        }\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# Ejecuci√≥n: por grupo (A/E) y por periodo(s)\n",
    "# =========================================================\n",
    "def ejecutar_consola(\n",
    "    grupo_seleccionado: str, remover_outliers: bool = True, k_iqr: float = 1.5\n",
    "):\n",
    "    \"\"\"\n",
    "    Imprime en consola las estad√≠sticas para cada periodo disponible del grupo indicado.\n",
    "    grupo_seleccionado: 'A' (Afluentes) o 'E' (Enrollment)\n",
    "    \"\"\"\n",
    "    dfs = cargar_vulnerabilidad_xlsx(XLSX_PATH)\n",
    "    df_personas = dfs.get(SHEET_PERSONAS, pd.DataFrame()).copy()\n",
    "    if df_personas.empty:\n",
    "        print(\"No se encontr√≥ la hoja 'Personas' o est√° vac√≠a.\")\n",
    "        return\n",
    "\n",
    "    # Periodos disponibles para el grupo\n",
    "    mask_grupo = df_personas[COL_TIPO].astype(str).str.strip() == str(\n",
    "        grupo_seleccionado\n",
    "    )\n",
    "    periodos = (\n",
    "        df_personas.loc[mask_grupo, COL_PERIODO]\n",
    "        .dropna()\n",
    "        .astype(str)\n",
    "        .drop_duplicates()\n",
    "        .sort_values()\n",
    "        .tolist()\n",
    "    )\n",
    "    if not periodos:\n",
    "        print(f\"No hay periodos para el grupo {grupo_seleccionado}.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== Grupo: {grupo_seleccionado} | Periodos: {', '.join(periodos)} ===\")\n",
    "    print(\n",
    "        f\"Par√°metros ingresos/deudas usados: a√±o={ANIO_FILTRO}, mes={MES_FILTRO}, salario_anual={SALARIO_MESES_ANO}x\\n\"\n",
    "    )\n",
    "\n",
    "    for periodo in periodos:\n",
    "        familias = obtener_datos_familias(dfs, periodo, grupo_seleccionado)\n",
    "        if familias.empty:\n",
    "            print(f\"[{periodo}] Sin familias.\")\n",
    "            continue\n",
    "\n",
    "        familias_sd = obtener_datos_salario_deuda_familia(dfs, familias)\n",
    "        hogares = _hogares_unicos_salario_deuda(familias_sd)\n",
    "\n",
    "        stats = calcular_estadisticas_ratios(\n",
    "            hogares, remover_outliers=remover_outliers, k_iqr=k_iqr\n",
    "        )\n",
    "\n",
    "        print(f\"--- Periodo {periodo} ---\")\n",
    "        print(f\"Total hogares √∫nicos: {len(hogares):,}\")\n",
    "        print(stats.to_string())\n",
    "        print()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# MAIN (ajusta grupo seg√∫n necesites)\n",
    "# =========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Ejecuta para Enrollment (E) y Afluentes (A) si quieres\n",
    "    ejecutar_consola(grupo_seleccionado=\"E\", remover_outliers=False, k_iqr=1.5)\n",
    "    # ejecutar_consola(grupo_seleccionado=\"A\", remover_outliers=True, k_iqr=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa81c049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando archivo: db\\vulnerabilidad.xlsx\n",
      "Total hogares filtrados: 8492\n",
      "Hogares 'raros' (n_personas_unicas < 2): 0\n",
      "Archivo generado: db\\hogares_raros_20250923_123733.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hogar_id</th>\n",
       "      <th>n_personas_unicas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hogar_id, n_personas_unicas]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hogar_id</th>\n",
       "      <th>fam_id</th>\n",
       "      <th>identificacion</th>\n",
       "      <th>tipo_empleo</th>\n",
       "      <th>salario</th>\n",
       "      <th>tipo_empleo_mes6</th>\n",
       "      <th>trabaja_mes6</th>\n",
       "      <th>identificacion_est</th>\n",
       "      <th>ced_padre</th>\n",
       "      <th>ced_madre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [hogar_id, fam_id, identificacion, tipo_empleo, salario, tipo_empleo_mes6, trabaja_mes6, identificacion_est, ced_padre, ced_madre]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ==========================\n",
    "# Config (ajusta si quieres)\n",
    "# ==========================\n",
    "DB_DIR = Path(\"db\")\n",
    "SHEET_UNIVERSO = \"Universo Familiares\"\n",
    "SHEET_PERSONAS = \"Personas\"  # opcional\n",
    "SHEET_INGRESOS = \"Ingresos\"  # requerido para 'trabajando'\n",
    "FILE_NAME = None  # si conoces el nombre, ponlo: \"vulnerabilidad.xlsx\"\n",
    "PERIODO = None  # ejemplo: \"2024-1\" o None para no filtrar por periodo\n",
    "ANIO = 2025\n",
    "MES = 6\n",
    "EMPLEOS_VALIDOS = [\"Relacion de Dependencia\", \"Afiliacion Voluntaria\"]\n",
    "\n",
    "# Filtros que quieres replicar del caso:\n",
    "CANT_PAPAS = 2  # 1, 2, o None (para Todos)\n",
    "CANT_PAPAS_TRAB = 1  # 0, 1, 2, o None (para Todos)\n",
    "TIPO_EMPLEO = \"Todos\"  # \"Todos\" | \"Relacion de Dependencia\" | \"Afiliacion Voluntaria\" | \"Desconocido\"\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Helpers\n",
    "# ==========================\n",
    "def make_hogar_id(ced_padre: str, ced_madre: str) -> str:\n",
    "    \"\"\"\n",
    "    Replica la idea de hogar √∫nico, independiente del orden.\n",
    "    Ignora \"0\" como no-informativo.\n",
    "    \"\"\"\n",
    "    a = str(ced_padre).strip()\n",
    "    b = str(ced_madre).strip()\n",
    "    ids = [x for x in (a, b) if x and x != \"0\"]\n",
    "    if not ids:\n",
    "        return \"\"\n",
    "    ids = sorted(ids)\n",
    "    return \"|\".join(ids)\n",
    "\n",
    "\n",
    "def load_excel_auto(db_dir: Path, file_name: str | None):\n",
    "    if file_name:\n",
    "        fp = db_dir / file_name\n",
    "        if not fp.exists():\n",
    "            raise FileNotFoundError(f\"No se encontr√≥: {fp}\")\n",
    "        return fp\n",
    "    cands = list(db_dir.glob(\"*.xls*\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"No se encontr√≥ ning√∫n Excel en db/\")\n",
    "    return cands[0]\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 1) Cargar hojas\n",
    "# ==========================\n",
    "file_path = load_excel_auto(DB_DIR, FILE_NAME)\n",
    "print(f\"Usando archivo: {file_path}\")\n",
    "\n",
    "xl = pd.ExcelFile(file_path)\n",
    "if SHEET_UNIVERSO not in xl.sheet_names:\n",
    "    raise KeyError(f\"No existe la hoja '{SHEET_UNIVERSO}' en el archivo.\")\n",
    "\n",
    "df_univ = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_UNIVERSO, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "df_univ.columns = [c.strip() for c in df_univ.columns]\n",
    "\n",
    "# PERSONAS (opcional, para filtrar por periodo)\n",
    "df_personas = None\n",
    "if SHEET_PERSONAS in xl.sheet_names:\n",
    "    df_personas = pd.read_excel(\n",
    "        file_path, sheet_name=SHEET_PERSONAS, dtype=str, engine=\"openpyxl\"\n",
    "    )\n",
    "    df_personas.columns = [c.strip() for c in df_personas.columns]\n",
    "\n",
    "# INGRESOS (requerido para n_trab y tipo)\n",
    "if SHEET_INGRESOS not in xl.sheet_names:\n",
    "    raise KeyError(f\"No existe la hoja '{SHEET_INGRESOS}' en el archivo.\")\n",
    "df_ing = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_INGRESOS, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "df_ing.columns = [c.strip() for c in df_ing.columns]\n",
    "\n",
    "# ==========================\n",
    "# 2) Normalizaci√≥n m√≠nima\n",
    "# ==========================\n",
    "# Universo\n",
    "req_cols_univ = {\"identificacion\", \"ced_padre\", \"ced_madre\"}\n",
    "lower_map = {c: c.lower() for c in df_univ.columns}\n",
    "df_univ = df_univ.rename(columns=lower_map)\n",
    "faltan = req_cols_univ - set(df_univ.columns)\n",
    "if faltan:\n",
    "    raise KeyError(f\"En '{SHEET_UNIVERSO}' faltan columnas: {faltan}\")\n",
    "\n",
    "df_univ[\"ced_padre\"] = df_univ[\"ced_padre\"].astype(str).str.strip()\n",
    "df_univ[\"ced_madre\"] = df_univ[\"ced_madre\"].astype(str).str.strip()\n",
    "df_univ[\"hogar_id\"] = df_univ.apply(\n",
    "    lambda r: make_hogar_id(r[\"ced_padre\"], r[\"ced_madre\"]), axis=1\n",
    ")\n",
    "df_univ = df_univ[\n",
    "    (df_univ[\"hogar_id\"] != \"\")\n",
    "    & ((df_univ[\"ced_padre\"] != \"0\") | (df_univ[\"ced_madre\"] != \"0\"))\n",
    "].copy()\n",
    "\n",
    "# Personas (opcional: filtrar por periodo)\n",
    "if df_personas is not None:\n",
    "    df_personas = df_personas.rename(\n",
    "        columns={c: c.lower() for c in df_personas.columns}\n",
    "    )\n",
    "    if PERIODO is not None:\n",
    "        if (\n",
    "            \"periodo\" not in df_personas.columns\n",
    "            or \"identificacion\" not in df_personas.columns\n",
    "        ):\n",
    "            raise KeyError(\n",
    "                f\"En '{SHEET_PERSONAS}' faltan 'periodo' y/o 'identificacion' para filtrar.\"\n",
    "            )\n",
    "        ids_periodo = (\n",
    "            df_personas.loc[df_personas[\"periodo\"] == str(PERIODO), \"identificacion\"]\n",
    "            .dropna()\n",
    "            .unique()\n",
    "        )\n",
    "        df_univ = df_univ[df_univ[\"identificacion\"].isin(ids_periodo)].copy()\n",
    "\n",
    "# Ingresos JUN/2025\n",
    "df_ing = df_ing.rename(columns={c: c.lower() for c in df_ing.columns})\n",
    "req_cols_ing = {\"identificacion\", \"anio\", \"mes\", \"tipo_empleo\", \"salario\"}\n",
    "faltan_ing = req_cols_ing - set(df_ing.columns)\n",
    "if faltan_ing:\n",
    "    raise KeyError(f\"En '{SHEET_INGRESOS}' faltan columnas: {faltan_ing}\")\n",
    "\n",
    "df_ing = df_ing[\n",
    "    (df_ing[\"anio\"].astype(str) == str(ANIO)) & (df_ing[\"mes\"].astype(str) == str(MES))\n",
    "].copy()\n",
    "df_ing[\"tipo_empleo\"] = df_ing[\"tipo_empleo\"].astype(str).str.strip()\n",
    "df_ing[\"salario\"] = pd.to_numeric(df_ing[\"salario\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 3) Aplicar filtros como en tu app (Enrollment)\n",
    "# ==========================\n",
    "# 3.1 Contar pap√°s DISTINCT (ignora \"0\")\n",
    "def count_distinct_parents(row):\n",
    "    s = {row[\"ced_padre\"], row[\"ced_madre\"]}\n",
    "    s.discard(\"0\")\n",
    "    return len(s)\n",
    "\n",
    "\n",
    "df_univ[\"n_papas\"] = df_univ.apply(count_distinct_parents, axis=1)\n",
    "if CANT_PAPAS in (1, 2):\n",
    "    df_univ = df_univ[df_univ[\"n_papas\"] == CANT_PAPAS].copy()\n",
    "\n",
    "# 3.2 Mapa hogar_id -> fam_id (padre/madre, sin \"0\")\n",
    "pairs = []\n",
    "for _, r in df_univ.iterrows():\n",
    "    if r[\"ced_padre\"] != \"0\":\n",
    "        pairs.append((r[\"hogar_id\"], r[\"ced_padre\"]))\n",
    "    if r[\"ced_madre\"] != \"0\":\n",
    "        pairs.append((r[\"hogar_id\"], r[\"ced_madre\"]))\n",
    "df_mapa = pd.DataFrame(pairs, columns=[\"hogar_id\", \"fam_id\"]).drop_duplicates()\n",
    "\n",
    "# 3.3 Merge con ingresos mes6\n",
    "df_emp = df_mapa.merge(\n",
    "    df_ing[[\"identificacion\", \"tipo_empleo\", \"salario\"]],\n",
    "    left_on=\"fam_id\",\n",
    "    right_on=\"identificacion\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df_emp[\"tipo_empleo_mes6\"] = df_emp[\"tipo_empleo\"].where(\n",
    "    df_emp[\"tipo_empleo\"].isin(EMPLEOS_VALIDOS), \"Desconocido\"\n",
    ")\n",
    "df_emp[\"trabaja_mes6\"] = df_emp[\"tipo_empleo_mes6\"].isin(EMPLEOS_VALIDOS)\n",
    "\n",
    "# 3.4 Filtro por tipo de empleo (si no es \"Todos\")\n",
    "if TIPO_EMPLEO != \"Todos\":\n",
    "    df_emp = df_emp[df_emp[\"tipo_empleo_mes6\"] == TIPO_EMPLEO].copy()\n",
    "\n",
    "# 3.5 Filtro por cantidad de pap√°s trabajando (0/1/2)\n",
    "agg = df_emp.groupby(\"hogar_id\", as_index=False).agg(n_trab=(\"trabaja_mes6\", \"sum\"))\n",
    "if CANT_PAPAS_TRAB in (0, 1, 2):\n",
    "    agg = agg[agg[\"n_trab\"] == CANT_PAPAS_TRAB].copy()\n",
    "\n",
    "hogares_filtrados = set(agg[\"hogar_id\"])\n",
    "df_emp = df_emp[df_emp[\"hogar_id\"].isin(hogares_filtrados)].copy()\n",
    "\n",
    "# ==========================\n",
    "# 4) Detecci√≥n de hogares \"raros\"\n",
    "#    (esperar√≠amos 2 personas √∫nicas; encontramos < 2)\n",
    "# ==========================\n",
    "by_hogar = (\n",
    "    df_emp.groupby(\"hogar_id\")[\"fam_id\"].nunique().reset_index(name=\"n_personas_unicas\")\n",
    ")\n",
    "hogares_raros = by_hogar[by_hogar[\"n_personas_unicas\"] < 2].copy()\n",
    "\n",
    "print(f\"Total hogares filtrados: {len(hogares_filtrados)}\")\n",
    "print(f\"Hogares 'raros' (n_personas_unicas < 2): {len(hogares_raros)}\")\n",
    "\n",
    "# Detalle por hogar raro: qu√© fam_id trae, con qu√© tipo_empleo y salario\n",
    "detalle_raros = df_emp[df_emp[\"hogar_id\"].isin(set(hogares_raros[\"hogar_id\"]))].copy()\n",
    "# agrega info original del universo (ced_padre/ced_madre) para diagn√≥sticos\n",
    "detalle_raros = detalle_raros.merge(\n",
    "    df_univ[[\"hogar_id\", \"identificacion\", \"ced_padre\", \"ced_madre\"]].drop_duplicates(),\n",
    "    on=\"hogar_id\",\n",
    "    how=\"left\",\n",
    "    suffixes=(\"\", \"_est\"),\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# 5) Exportar a Excel (2 hojas)\n",
    "# ==========================\n",
    "out_name = f\"hogares_raros_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "out_path = file_path.parent / out_name\n",
    "\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as xw:\n",
    "    hogares_raros.to_excel(xw, index=False, sheet_name=\"hogares_raros_resumen\")\n",
    "    detalle_raros.to_excel(xw, index=False, sheet_name=\"hogares_raros_detalle\")\n",
    "\n",
    "print(f\"Archivo generado: {out_path}\")\n",
    "display(hogares_raros.head(10))\n",
    "display(detalle_raros.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4ed58ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Columnas no presentes en detalle_multi y ser√°n omitidas: ['identificacion']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fam_id</th>\n",
       "      <th>hogar_id</th>\n",
       "      <th>rol_en_hogar</th>\n",
       "      <th>trabaja_mes6</th>\n",
       "      <th>tipo_empleo_mes6</th>\n",
       "      <th>salario</th>\n",
       "      <th>ced_padre</th>\n",
       "      <th>ced_madre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0502367485</td>\n",
       "      <td>0502367485|0502506215</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>470.00</td>\n",
       "      <td>0502506215</td>\n",
       "      <td>0502367485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0502367485</td>\n",
       "      <td>0502367485|1803303641</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>470.00</td>\n",
       "      <td>1803303641</td>\n",
       "      <td>0502367485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0603142324</td>\n",
       "      <td>0603142324|1001987864</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>550.00</td>\n",
       "      <td>1001987864</td>\n",
       "      <td>0603142324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0603142324</td>\n",
       "      <td>0603142324|1714146741</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>550.00</td>\n",
       "      <td>1714146741</td>\n",
       "      <td>0603142324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1001660545</td>\n",
       "      <td>1001660545|1002120432</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001660545</td>\n",
       "      <td>1002120432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1001660545</td>\n",
       "      <td>1001660545|1709880262</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001660545</td>\n",
       "      <td>1709880262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1002177341</td>\n",
       "      <td>1002177341|1002524872</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002177341</td>\n",
       "      <td>1002524872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1002177341</td>\n",
       "      <td>1002177341|1002698551</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002177341</td>\n",
       "      <td>1002698551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1002527750</td>\n",
       "      <td>1001986254|1002527750</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1001986254</td>\n",
       "      <td>1002527750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1002527750</td>\n",
       "      <td>1002527750|1705318283</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1705318283</td>\n",
       "      <td>1002527750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1202488100</td>\n",
       "      <td>0906716774|1202488100</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>470.00</td>\n",
       "      <td>0906716774</td>\n",
       "      <td>1202488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1202488100</td>\n",
       "      <td>0909531212|1202488100</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>470.00</td>\n",
       "      <td>0909531212</td>\n",
       "      <td>1202488100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1308909264</td>\n",
       "      <td>1308909264|1705620431</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>1676.00</td>\n",
       "      <td>1705620431</td>\n",
       "      <td>1308909264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1308909264</td>\n",
       "      <td>1308909264|1709536690</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>1676.00</td>\n",
       "      <td>1709536690</td>\n",
       "      <td>1308909264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1600541526</td>\n",
       "      <td>1002355236|1600541526</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>986.00</td>\n",
       "      <td>1002355236</td>\n",
       "      <td>1600541526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1600541526</td>\n",
       "      <td>1600541526|1802684223</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Relacion de Dependencia</td>\n",
       "      <td>986.00</td>\n",
       "      <td>1802684223</td>\n",
       "      <td>1600541526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1706952627</td>\n",
       "      <td>1706952627|1707259238</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>511.35</td>\n",
       "      <td>1707259238</td>\n",
       "      <td>1706952627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1706952627</td>\n",
       "      <td>1706952627|1710553932</td>\n",
       "      <td>madre</td>\n",
       "      <td>True</td>\n",
       "      <td>Afiliacion Voluntaria</td>\n",
       "      <td>511.35</td>\n",
       "      <td>1710553932</td>\n",
       "      <td>1706952627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1709443020</td>\n",
       "      <td>1709443020|1712670189</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1709443020</td>\n",
       "      <td>1712670189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1709443020</td>\n",
       "      <td>1709443020|1715735526</td>\n",
       "      <td>padre</td>\n",
       "      <td>False</td>\n",
       "      <td>Desconocido</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1709443020</td>\n",
       "      <td>1715735526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        fam_id               hogar_id rol_en_hogar  trabaja_mes6  \\\n",
       "0   0502367485  0502367485|0502506215        madre          True   \n",
       "1   0502367485  0502367485|1803303641        madre          True   \n",
       "44  0603142324  0603142324|1001987864        madre          True   \n",
       "43  0603142324  0603142324|1714146741        madre          True   \n",
       "7   1001660545  1001660545|1002120432        padre         False   \n",
       "5   1001660545  1001660545|1709880262        padre         False   \n",
       "8   1002177341  1002177341|1002524872        padre         False   \n",
       "6   1002177341  1002177341|1002698551        padre         False   \n",
       "11  1002527750  1001986254|1002527750        madre          True   \n",
       "46  1002527750  1002527750|1705318283        madre          True   \n",
       "3   1202488100  0906716774|1202488100        madre          True   \n",
       "4   1202488100  0909531212|1202488100        madre          True   \n",
       "40  1308909264  1308909264|1705620431        madre          True   \n",
       "41  1308909264  1308909264|1709536690        madre          True   \n",
       "9   1600541526  1002355236|1600541526        madre          True   \n",
       "10  1600541526  1600541526|1802684223        madre          True   \n",
       "16  1706952627  1706952627|1707259238        madre          True   \n",
       "13  1706952627  1706952627|1710553932        madre          True   \n",
       "31  1709443020  1709443020|1712670189        padre         False   \n",
       "12  1709443020  1709443020|1715735526        padre         False   \n",
       "\n",
       "           tipo_empleo_mes6  salario   ced_padre   ced_madre  \n",
       "0     Afiliacion Voluntaria   470.00  0502506215  0502367485  \n",
       "1     Afiliacion Voluntaria   470.00  1803303641  0502367485  \n",
       "44  Relacion de Dependencia   550.00  1001987864  0603142324  \n",
       "43  Relacion de Dependencia   550.00  1714146741  0603142324  \n",
       "7               Desconocido      NaN  1001660545  1002120432  \n",
       "5               Desconocido      NaN  1001660545  1709880262  \n",
       "8               Desconocido      NaN  1002177341  1002524872  \n",
       "6               Desconocido      NaN  1002177341  1002698551  \n",
       "11  Relacion de Dependencia  1000.00  1001986254  1002527750  \n",
       "46  Relacion de Dependencia  1000.00  1705318283  1002527750  \n",
       "3     Afiliacion Voluntaria   470.00  0906716774  1202488100  \n",
       "4     Afiliacion Voluntaria   470.00  0909531212  1202488100  \n",
       "40  Relacion de Dependencia  1676.00  1705620431  1308909264  \n",
       "41  Relacion de Dependencia  1676.00  1709536690  1308909264  \n",
       "9   Relacion de Dependencia   986.00  1002355236  1600541526  \n",
       "10  Relacion de Dependencia   986.00  1802684223  1600541526  \n",
       "16    Afiliacion Voluntaria   511.35  1707259238  1706952627  \n",
       "13    Afiliacion Voluntaria   511.35  1710553932  1706952627  \n",
       "31              Desconocido      NaN  1709443020  1712670189  \n",
       "12              Desconocido      NaN  1709443020  1715735526  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo generado: familiares_multi_hogar_20250923_124310.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------\n",
    "# 3D) orden y columnas √∫tiles (robusto a columnas faltantes/acentos)\n",
    "# -------------------------------------------------\n",
    "# Normaliza posibles variantes con acento\n",
    "def _normalize_cols(df):\n",
    "    ren = {}\n",
    "    for c in df.columns:\n",
    "        cl = c.lower().strip()\n",
    "        # mapea variantes comunes\n",
    "        if cl in {\"identificaci√≥n\", \"identificacion\"}:\n",
    "            ren[c] = \"identificacion\"\n",
    "        elif cl in {\"cedula_padre\", \"c√©dula_padre\"}:\n",
    "            ren[c] = \"ced_padre\"\n",
    "        elif cl in {\"cedula_madre\", \"c√©dula_madre\"}:\n",
    "            ren[c] = \"ced_madre\"\n",
    "        else:\n",
    "            ren[c] = c  # no cambiar\n",
    "    return df.rename(columns=ren)\n",
    "\n",
    "\n",
    "detalle_multi = _normalize_cols(detalle_multi)\n",
    "df_univ = _normalize_cols(df_univ)\n",
    "\n",
    "cols_show = [\n",
    "    \"fam_id\",\n",
    "    \"hogar_id\",\n",
    "    \"rol_en_hogar\",\n",
    "    \"trabaja_mes6\",\n",
    "    \"tipo_empleo_mes6\",\n",
    "    \"salario\",\n",
    "    \"identificacion\",\n",
    "    \"ced_padre\",\n",
    "    \"ced_madre\",\n",
    "]\n",
    "\n",
    "# Qu√© columnas realmente est√°n\n",
    "existentes = [c for c in cols_show if c in detalle_multi.columns]\n",
    "faltantes = [c for c in cols_show if c not in detalle_multi.columns]\n",
    "if faltantes:\n",
    "    print(\"‚ö†Ô∏è Columnas no presentes en detalle_multi y ser√°n omitidas:\", faltantes)\n",
    "\n",
    "detalle_multi = detalle_multi[existentes].sort_values([\"fam_id\", \"hogar_id\"])\n",
    "\n",
    "display(detalle_multi.head(20))\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4) Exportar a Excel: resumen y detalle\n",
    "# -------------------------------------------------\n",
    "out_name = f\"familiares_multi_hogar_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "with pd.ExcelWriter(out_name, engine=\"openpyxl\") as xw:\n",
    "    multi_hogar.to_excel(xw, index=False, sheet_name=\"resumen_fam_multi_hogar\")\n",
    "    detalle_multi.to_excel(xw, index=False, sheet_name=\"detalle_fam_multi_hogar\")\n",
    "\n",
    "print(f\"Archivo generado: {out_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c32e7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando archivo: db\\vulnerabilidad.xlsx\n",
      "Identificaciones en facultad 'FACULTAD DE CIENCIAS DE LA SALUD': 2145\n",
      "Hogares (tras filtro 2 pap√°s): 1988\n",
      "Hogares filtrados finales: 842\n",
      "Familiares √öNICOS - Trabajando: 841\n",
      "Familiares √öNICOS - No Trabajando: 842\n",
      "Total √öNICOS: 1683\n",
      "Esperado (= hogares √ó 2): 1684\n",
      "Familiares TRABAJANDO en >1 hogar: 1\n",
      "['1716691843']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['identificacion'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 241\u001b[39m\n\u001b[32m    229\u001b[39m detalle[\u001b[33m\"\u001b[39m\u001b[33mrol_en_hogar\u001b[39m\u001b[33m\"\u001b[39m] = detalle.apply(rol_en_hogar, axis=\u001b[32m1\u001b[39m)\n\u001b[32m    231\u001b[39m cols_show = [\n\u001b[32m    232\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfam_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    233\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhogar_id\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    239\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mced_madre\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    240\u001b[39m ]\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m detalle = \u001b[43mdetalle\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcols_show\u001b[49m\u001b[43m]\u001b[49m.sort_values([\u001b[33m\"\u001b[39m\u001b[33mfam_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhogar_id\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    243\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== DETALLE DE PERSONAS TRABAJANDO MULTI-HOGAR ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    244\u001b[39m display(detalle.head(\u001b[32m50\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andreidavid.flores\\Downloads\\Work\\Vulnerabilidad\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andreidavid.flores\\Downloads\\Work\\Vulnerabilidad\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\andreidavid.flores\\Downloads\\Work\\Vulnerabilidad\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['identificacion'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ==========================\n",
    "# Config\n",
    "# ==========================\n",
    "DB_DIR = Path(\"db\")\n",
    "FILE_NAME =\"vulnerabilidad.xlsx\"\n",
    "SHEET_UNIVERSO = \"Universo Familiares\"\n",
    "SHEET_PERSONAS = \"Personas\"\n",
    "SHEET_INGRESOS = \"Ingresos\"\n",
    "FACULTAD_NAME = \"FACULTAD DE CIENCIAS DE LA SALUD\"\n",
    "\n",
    "ANIO = 2025\n",
    "MES = 6\n",
    "EMPLEOS_VALIDOS = [\"Relacion de Dependencia\", \"Afiliacion Voluntaria\"]\n",
    "\n",
    "# Filtros tal como los tienes:\n",
    "CANT_PAPAS = 2  # 1, 2 o None (\"Todos\")\n",
    "CANT_PAPAS_TRAB = 1  # 0, 1, 2 o None (\"Todos\")\n",
    "TIPO_EMPLEO = \"Todos\"  # \"Todos\" | \"Relacion de Dependencia\" | \"Afiliacion Voluntaria\" | \"Desconocido\"\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# Helpers\n",
    "# ==========================\n",
    "def load_excel_auto(db_dir: Path, file_name: str | None) -> Path:\n",
    "    if file_name:\n",
    "        fp = db_dir / file_name\n",
    "        if not fp.exists():\n",
    "            raise FileNotFoundError(f\"No se encontr√≥: {fp}\")\n",
    "        return fp\n",
    "    cands = list(db_dir.glob(\"*.xls*\"))\n",
    "    if not cands:\n",
    "        raise FileNotFoundError(\"No se encontr√≥ ning√∫n Excel en db/\")\n",
    "    return cands[0]\n",
    "\n",
    "\n",
    "def normalize_cols(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # normaliza a min√∫sculas y mapea variantes con acento\n",
    "    ren = {}\n",
    "    for c in df.columns:\n",
    "        cl = c.strip().lower()\n",
    "        if cl in {\"identificaci√≥n\", \"identificacion\"}:\n",
    "            ren[c] = \"identificacion\"\n",
    "        elif cl in {\"facultad\"}:\n",
    "            ren[c] = \"facultad\"\n",
    "        elif cl in {\"c√©dula_padre\", \"cedula_padre\"}:\n",
    "            ren[c] = \"ced_padre\"\n",
    "        elif cl in {\"c√©dula_madre\", \"cedula_madre\"}:\n",
    "            ren[c] = \"ced_madre\"\n",
    "        elif cl in {\"a√±o\"}:\n",
    "            ren[c] = \"anio\"\n",
    "        else:\n",
    "            ren[c] = cl\n",
    "    return df.rename(columns=ren)\n",
    "\n",
    "\n",
    "def make_hogar_id(ced_padre: str, ced_madre: str) -> str:\n",
    "    a = str(ced_padre).strip()\n",
    "    b = str(ced_madre).strip()\n",
    "    ids = [x for x in (a, b) if x and x != \"0\"]\n",
    "    if not ids:\n",
    "        return \"\"\n",
    "    return \"|\".join(sorted(ids))\n",
    "\n",
    "\n",
    "def count_distinct_parents(row) -> int:\n",
    "    s = {row[\"ced_padre\"], row[\"ced_madre\"]}\n",
    "    s.discard(\"0\")\n",
    "    return len(s)\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# 1) Cargar hojas\n",
    "# ==========================\n",
    "file_path = load_excel_auto(DB_DIR, FILE_NAME)\n",
    "print(f\"Usando archivo: {file_path}\")\n",
    "\n",
    "xl = pd.ExcelFile(file_path)\n",
    "for sh in (SHEET_UNIVERSO, SHEET_PERSONAS, SHEET_INGRESOS):\n",
    "    if sh not in xl.sheet_names:\n",
    "        raise KeyError(f\"No existe la hoja '{sh}' en el archivo.\")\n",
    "\n",
    "df_univ = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_UNIVERSO, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "df_per = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_PERSONAS, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "df_ing = pd.read_excel(\n",
    "    file_path, sheet_name=SHEET_INGRESOS, dtype=str, engine=\"openpyxl\"\n",
    ")\n",
    "\n",
    "df_univ = normalize_cols(df_univ)\n",
    "df_per = normalize_cols(df_per)\n",
    "df_ing = normalize_cols(df_ing)\n",
    "\n",
    "# Validaci√≥n m√≠nima\n",
    "for req, df_ in (\n",
    "    ({\"identificacion\", \"ced_padre\", \"ced_madre\"}, df_univ),\n",
    "    ({\"identificacion\", \"facultad\"}, df_per),\n",
    "    ({\"identificacion\", \"anio\", \"mes\", \"tipo_empleo\", \"salario\"}, df_ing),\n",
    "):\n",
    "    faltan = req - set(df_.columns)\n",
    "    if faltan:\n",
    "        raise KeyError(\n",
    "            f\"Faltan columnas {faltan} en una de las hojas correspondientes.\"\n",
    "        )\n",
    "\n",
    "# ==========================\n",
    "# 2) Filtrar Personas por facultad\n",
    "# ==========================\n",
    "ids_facultad = (\n",
    "    df_per.loc[\n",
    "        df_per[\"facultad\"].astype(str).str.strip().str.lower() == FACULTAD_NAME.lower(),\n",
    "        \"identificacion\",\n",
    "    ]\n",
    "    .dropna()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "print(f\"Identificaciones en facultad '{FACULTAD_NAME}': {len(ids_facultad)}\")\n",
    "\n",
    "# ==========================\n",
    "# 3) Universo filtrado por esos estudiantes\n",
    "# ==========================\n",
    "u = df_univ[df_univ[\"identificacion\"].isin(ids_facultad)].copy()\n",
    "u[\"ced_padre\"] = u[\"ced_padre\"].astype(str).str.strip()\n",
    "u[\"ced_madre\"] = u[\"ced_madre\"].astype(str).str.strip()\n",
    "u[\"hogar_id\"] = u.apply(lambda r: make_hogar_id(r[\"ced_padre\"], r[\"ced_madre\"]), axis=1)\n",
    "u = u[\n",
    "    (u[\"hogar_id\"] != \"\") & ((u[\"ced_padre\"] != \"0\") | (u[\"ced_madre\"] != \"0\"))\n",
    "].copy()\n",
    "\n",
    "# contar pap√°s DISTINCT y filtrar 2\n",
    "u[\"n_papas\"] = u.apply(count_distinct_parents, axis=1)\n",
    "if CANT_PAPAS in (1, 2):\n",
    "    u = u[u[\"n_papas\"] == CANT_PAPAS].copy()\n",
    "\n",
    "print(\"Hogares (tras filtro 2 pap√°s):\", u[\"hogar_id\"].nunique())\n",
    "\n",
    "# ==========================\n",
    "# 4) Ingresos JUN/2025 y merge a familiares\n",
    "# ==========================\n",
    "ing6 = df_ing[\n",
    "    (df_ing[\"anio\"].astype(str) == str(ANIO)) & (df_ing[\"mes\"].astype(str) == str(MES))\n",
    "].copy()\n",
    "ing6[\"tipo_empleo\"] = ing6[\"tipo_empleo\"].astype(str).str.strip()\n",
    "ing6[\"salario\"] = pd.to_numeric(ing6[\"salario\"], errors=\"coerce\")\n",
    "\n",
    "pairs = []\n",
    "for _, r in u.iterrows():\n",
    "    if r[\"ced_padre\"] != \"0\":\n",
    "        pairs.append((r[\"hogar_id\"], r[\"ced_padre\"]))\n",
    "    if r[\"ced_madre\"] != \"0\":\n",
    "        pairs.append((r[\"hogar_id\"], r[\"ced_madre\"]))\n",
    "df_mapa = pd.DataFrame(pairs, columns=[\"hogar_id\", \"fam_id\"]).drop_duplicates()\n",
    "\n",
    "df_emp = df_mapa.merge(\n",
    "    ing6[[\"identificacion\", \"tipo_empleo\", \"salario\"]],\n",
    "    left_on=\"fam_id\",\n",
    "    right_on=\"identificacion\",\n",
    "    how=\"left\",\n",
    ")\n",
    "df_emp[\"tipo_empleo_mes6\"] = df_emp[\"tipo_empleo\"].where(\n",
    "    df_emp[\"tipo_empleo\"].isin(EMPLEOS_VALIDOS), \"Desconocido\"\n",
    ")\n",
    "df_emp[\"trabaja_mes6\"] = df_emp[\"tipo_empleo_mes6\"].isin(EMPLEOS_VALIDOS)\n",
    "\n",
    "# filtro por tipo empleo (si aplica)\n",
    "if TIPO_EMPLEO != \"Todos\":\n",
    "    df_emp = df_emp[df_emp[\"tipo_empleo_mes6\"] == TIPO_EMPLEO].copy()\n",
    "\n",
    "# hogares con exactamente 1 trabajando\n",
    "agg = df_emp.groupby(\"hogar_id\", as_index=False).agg(n_trab=(\"trabaja_mes6\", \"sum\"))\n",
    "if CANT_PAPAS_TRAB in (0, 1, 2):\n",
    "    agg = agg[agg[\"n_trab\"] == CANT_PAPAS_TRAB].copy()\n",
    "\n",
    "hogares_filtrados = set(agg[\"hogar_id\"])\n",
    "df_emp = df_emp[df_emp[\"hogar_id\"].isin(hogares_filtrados)].copy()\n",
    "\n",
    "print(\"Hogares filtrados finales:\", len(hogares_filtrados))\n",
    "\n",
    "# ==========================\n",
    "# 5) Ver la asimetr√≠a y detectar al/los causantes (TRABAJANDO)\n",
    "# ==========================\n",
    "# Esperado (si no hay solapes): #hogares trabajando √∫nicos = #hogares\n",
    "trab = df_emp[df_emp[\"trabaja_mes6\"]].copy()\n",
    "no_trab = df_emp[~df_emp[\"trabaja_mes6\"]].copy()\n",
    "\n",
    "trab_unicos = trab[\"fam_id\"].nunique()\n",
    "no_trab_unicos = no_trab[\"fam_id\"].nunique()\n",
    "\n",
    "print(\"Familiares √öNICOS - Trabajando:\", trab_unicos)\n",
    "print(\"Familiares √öNICOS - No Trabajando:\", no_trab_unicos)\n",
    "print(\"Total √öNICOS:\", trab_unicos + no_trab_unicos)\n",
    "print(\"Esperado (= hogares √ó 2):\", len(hogares_filtrados) * 2)\n",
    "\n",
    "# fam_id en >1 hogar dentro del set TRABAJANDO (estos causan que 842 -> 841)\n",
    "solapes_trab = trab.groupby(\"fam_id\")[\"hogar_id\"].nunique() > 1\n",
    "fam_multi_trab = solapes_trab[solapes_trab].index.tolist()\n",
    "\n",
    "print(\"Familiares TRABAJANDO en >1 hogar:\", len(fam_multi_trab))\n",
    "print(fam_multi_trab[:10])\n",
    "\n",
    "# ==========================\n",
    "# 6) Detalle del/los fam_id problem√°ticos\n",
    "# ==========================\n",
    "detalle = trab[trab[\"fam_id\"].isin(fam_multi_trab)].copy()\n",
    "# a√±ade datos del universo para ver qu√© estudiante(s) los vincularon\n",
    "detalle = detalle.merge(\n",
    "    u[[\"hogar_id\", \"identificacion\", \"ced_padre\", \"ced_madre\"]].drop_duplicates(),\n",
    "    on=\"hogar_id\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "\n",
    "# rol en el hogar para mayor claridad\n",
    "def rol_en_hogar(row):\n",
    "    if row[\"fam_id\"] == row[\"ced_padre\"]:\n",
    "        return \"padre\"\n",
    "    if row[\"fam_id\"] == row[\"ced_madre\"]:\n",
    "        return \"madre\"\n",
    "    return \"desconocido\"\n",
    "\n",
    "\n",
    "detalle[\"rol_en_hogar\"] = detalle.apply(rol_en_hogar, axis=1)\n",
    "\n",
    "cols_show = [\n",
    "    \"fam_id\",\n",
    "    \"hogar_id\",\n",
    "    \"rol_en_hogar\",\n",
    "    \"tipo_empleo_mes6\",\n",
    "    \"salario\",\n",
    "    \"identificacion\",\n",
    "    \"ced_padre\",\n",
    "    \"ced_madre\",\n",
    "]\n",
    "detalle = detalle[cols_show].sort_values([\"fam_id\", \"hogar_id\"])\n",
    "\n",
    "print(\"\\n=== DETALLE DE PERSONAS TRABAJANDO MULTI-HOGAR ===\")\n",
    "display(detalle.head(50))\n",
    "\n",
    "# ==========================\n",
    "# 7) Exportar a Excel\n",
    "# ==========================\n",
    "out_name = f\"salud_personas_trabajando_multi_hogar_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx\"\n",
    "out_path = file_path.parent / out_name\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as xw:\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"hogares_filtrados\": [len(hogares_filtrados)],\n",
    "            \"trabajando_unicos\": [trab_unicos],\n",
    "            \"no_trabajando_unicos\": [no_trab_unicos],\n",
    "            \"total_unicos\": [trab_unicos + no_trab_unicos],\n",
    "            \"esperado_hogares_x2\": [len(hogares_filtrados) * 2],\n",
    "        }\n",
    "    ).to_excel(xw, index=False, sheet_name=\"resumen\")\n",
    "    pd.DataFrame({\"fam_id_multi_trab\": fam_multi_trab}).to_excel(\n",
    "        xw, index=False, sheet_name=\"ids_multi_trab\"\n",
    "    )\n",
    "    detalle.to_excel(xw, index=False, sheet_name=\"detalle_multi_trab\")\n",
    "\n",
    "print(f\"\\nArchivo generado: {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
